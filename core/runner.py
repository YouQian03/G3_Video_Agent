# core/runner.py
from pathlib import Path
import shutil
import subprocess
import time
import os
import requests 

from .workflow_io import save_workflow, load_workflow


def ensure_videos_dir(job_dir: Path) -> Path:
    videos_dir = job_dir / "videos"
    videos_dir.mkdir(parents=True, exist_ok=True)
    return videos_dir


def mock_stylize_frame(job_dir: Path, shot: dict) -> str:
    src = job_dir / shot["assets"]["first_frame"]
    if not src.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° first_frameï¼š{src}")

    dst = job_dir / "stylized_frames" / f"{shot['shot_id']}.png"
    dst.parent.mkdir(parents=True, exist_ok=True)
    shutil.copyfile(src, dst)
    return f"stylized_frames/{dst.name}"


def mock_generate_video(job_dir: Path, shot: dict) -> str:
    videos_dir = ensure_videos_dir(job_dir)
    out_path = videos_dir / f"{shot['shot_id']}.mp4"
    
    # æ ¸å¿ƒï¼šå¯åŠ¨å‰æ¸…åœºï¼Œç¡®ä¿çŠ¶æ€åŒæ­¥å‡†ç¡®
    if out_path.exists():
        os.remove(out_path)

    src_video = job_dir / "input.mp4"
    if not src_video.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æºè§†é¢‘ï¼š{src_video}")
    ffmpeg = "/opt/homebrew/bin/ffmpeg"
    cmd = [
        ffmpeg, "-y",
        "-i", str(src_video),
        "-t", "1.0",
        "-c", "copy",
        str(out_path)
    ]
    subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    return f"videos/{out_path.name}"


def veo_generate_video(job_dir: Path, wf: dict, shot: dict) -> str:
    """
    Veo 3.1 å›¾ç”Ÿè§†é¢‘ - å¥å£®æ€§å¢žå¼ºç‰ˆ
    1. å¢žåŠ å®‰å…¨è¿‡æ»¤æ£€æŸ¥ï¼Œé˜²æ­¢ç©ºå¼•ç”¨å´©æºƒ
    2. ç”Ÿæˆå‰æ¸…ç†æ—§æ–‡ä»¶
    """
    from google import genai
    from google.genai import types

    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise RuntimeError("æ²¡æœ‰æ£€æµ‹åˆ° GEMINI_API_KEY çŽ¯å¢ƒå˜é‡")

    videos_dir = ensure_videos_dir(job_dir)
    out_path = videos_dir / f"{shot['shot_id']}.mp4"

    # --- å¯åŠ¨å‰æ¸…åœº ---
    if out_path.exists():
        print(f"ðŸ—‘ï¸ å‡†å¤‡ç”Ÿæˆæ–°è§†é¢‘ï¼Œæ¸…ç†æ—§æ–‡ä»¶: {out_path}")
        os.remove(out_path)

    img_rel = shot.get("assets", {}).get("stylized_frame")
    if not img_rel:
        raise RuntimeError("shot ç¼ºå°‘ assets.stylized_frame")
    img_path = job_dir / img_rel

    # 1. åˆå§‹åŒ–å®¢æˆ·ç«¯ (ç”Ÿæˆé˜¶æ®µç”¨ v1alpha)
    client = genai.Client(api_key=api_key, http_options={'api_version': 'v1alpha'})

    # 2. å‘èµ· Veo è¯·æ±‚
    print(f"ðŸš€ å‘èµ· Veo è¯·æ±‚ (Shot: {shot['shot_id']})...")
    operation = client.models.generate_videos(
        model="veo-3.1-generate-preview", 
        prompt=f"Cinematic video, {shot.get('description', '')}. Style: {wf.get('global', {}).get('style_prompt', '')}.",
        image=types.Image(
            image_bytes=img_path.read_bytes(),
            mime_type="image/png"
        ),
        config=types.GenerateVideosConfig(
            number_of_videos=1,
            duration_seconds=6.0
        ),
    )

    # 3. è½®è¯¢çŠ¶æ€
    print(f"â³ ä»»åŠ¡å·²æäº¤ï¼ŒVeo æ­£åœ¨ç”Ÿæˆè§†é¢‘ (çº¦ 1-3 åˆ†é’Ÿ)...")
    while not operation.done:
        time.sleep(20)
        operation = client.operations.get(operation)
        print(f"â³ ä»åœ¨ç”Ÿæˆä¸­...")

    if operation.error:
        raise RuntimeError(f"Veo åŽç«¯æŠ¥é”™: {operation.error}")

    # 4. ç»“æžœæ£€æŸ¥ (é‡è¦ä¿®å¤ç‚¹ï¼šé˜²æ­¢å®‰å…¨è¿‡æ»¤å¯¼è‡´çš„å´©æºƒ)
    resp = operation.response
    if not resp or not hasattr(resp, 'generated_videos') or not resp.generated_videos:
        # å¦‚æžœæ¨¡åž‹å› ä¸ºå®‰å…¨ç­–ç•¥æ‹’ç»ç”Ÿæˆï¼Œresp.generated_videos ä¼šæ˜¯ None æˆ–ç©ºåˆ—è¡¨
        raise RuntimeError("Veo æœªè¿”å›žè§†é¢‘å†…å®¹ã€‚è¿™é€šå¸¸ç”±äºŽ Prompt è§¦å‘äº†å®‰å…¨è¿‡æ»¤æˆ–æ¨¡åž‹ç”Ÿæˆå¼‚å¸¸ã€‚")

    video_obj = resp.generated_videos[0].video
    
    file_id = getattr(video_obj, 'name', None)
    if not file_id and hasattr(video_obj, 'uri'):
        file_id = f"files/{video_obj.uri.split('/')[-1]}"

    if not file_id:
        raise RuntimeError(f"æ— æ³•å®šä½ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶: {video_obj}")

    # 5. ä¸‹è½½è§†é¢‘
    print(f"âœ… ç”ŸæˆæˆåŠŸï¼Œæ­£åœ¨ä¸‹è½½è§†é¢‘...")
    download_url = f"https://generativelanguage.googleapis.com/v1beta/{file_id}"
    query_params = {'alt': 'media', 'key': api_key}

    try:
        response = requests.get(download_url, params=query_params, stream=True)
        if response.status_code != 200:
            alpha_url = f"https://generativelanguage.googleapis.com/v1alpha/{file_id}"
            response = requests.get(alpha_url, params=query_params, stream=True)

        if response.status_code == 200:
            with open(out_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=1024*1024): 
                    if chunk: f.write(chunk)
            print(f"ðŸ’¾ è§†é¢‘ç”Ÿæˆå¹¶ä¸‹è½½æˆåŠŸï¼æœ¬åœ°è·¯å¾„: {out_path}")
        else:
            raise RuntimeError(f"ä¸‹è½½å¤±è´¥ã€‚çŠ¶æ€ç : {response.status_code}")
            
    except Exception as e:
        print(f"âŒ ä¸‹è½½è¿‡ç¨‹å¼‚å¸¸: {e}")
        raise e

    return f"videos/{out_path.name}"


def run_stylize(job_dir: Path, wf: dict, target_shot: str | None = None) -> None:
    for shot in wf.get("shots", []):
        sid = shot.get("shot_id")
        if target_shot and sid != target_shot: continue
        status = shot.get("status", {}).get("stylize", "NOT_STARTED")
        if not target_shot and status not in ("NOT_STARTED", "FAILED"): continue
        shot.setdefault("status", {})["stylize"] = "RUNNING"
        save_workflow(job_dir, wf)
        try:
            rel_path = mock_stylize_frame(job_dir, shot)
            shot.setdefault("assets", {})["stylized_frame"] = rel_path
            shot["status"]["stylize"] = "SUCCESS"
            print(f"âœ… stylize SUCCESS: {sid} -> {rel_path}")
        except Exception as e:
            shot["status"]["stylize"] = "FAILED"
            shot.setdefault("errors", {})["stylize"] = str(e)
            print(f"âŒ stylize FAILED: {sid} -> {e}")
        save_workflow(job_dir, wf)


def run_video_generate(job_dir: Path, wf: dict, target_shot: str | None = None) -> None:
    for shot in wf.get("shots", []):
        sid = shot.get("shot_id")
        if target_shot and sid != target_shot: continue
        status = shot.get("status", {}).get("video_generate", "NOT_STARTED")
        if not target_shot and status not in ("NOT_STARTED", "FAILED"): continue
        shot.setdefault("status", {})["video_generate"] = "RUNNING"
        save_workflow(job_dir, wf)
        try:
            video_model = wf.get("global", {}).get("video_model", "mock")
            if video_model == "veo":
                print(f"ðŸ”¥ æ‰§è¡Œ Veo ä»»åŠ¡: {sid}")
                rel_video_path = veo_generate_video(job_dir, wf, shot)
            else:
                rel_video_path = mock_generate_video(job_dir, shot)
            shot.setdefault("assets", {})["video"] = rel_video_path
            shot["status"]["video_generate"] = "SUCCESS"
            print(f"âœ… video_generate SUCCESS: {sid}")
        except Exception as e:
            import traceback
            shot["status"]["video_generate"] = "FAILED"
            shot.setdefault("errors", {})["video_generate"] = str(e)
            print(f"âŒ video_generate FAILED: {sid}")
            traceback.print_exc()
        save_workflow(job_dir, wf)


def run_pipeline(job_dir: Path, target_shot: str | None = None) -> None:
    wf = load_workflow(job_dir)
    run_stylize(job_dir, wf, target_shot=target_shot)
    wf = load_workflow(job_dir)
    run_video_generate(job_dir, wf, target_shot=target_shot)



