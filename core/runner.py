# core/runner.py
from pathlib import Path
import shutil
import subprocess
import time

from .workflow_io import save_workflow, load_workflow


def ensure_videos_dir(job_dir: Path) -> Path:
    videos_dir = job_dir / "videos"
    videos_dir.mkdir(parents=True, exist_ok=True)
    return videos_dir


def mock_stylize_frame(job_dir: Path, shot: dict) -> str:
    src = job_dir / shot["assets"]["first_frame"]
    if not src.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° first_frameï¼š{src}")

    dst = job_dir / "stylized_frames" / f"{shot['shot_id']}.png"
    dst.parent.mkdir(parents=True, exist_ok=True)
    shutil.copyfile(src, dst)
    return f"stylized_frames/{dst.name}"


def mock_generate_video(job_dir: Path, shot: dict) -> str:
    """
    Demo ç‰ˆï¼šç”¨ input.mp4 çš„å‰ 1 ç§’åšå ä½è§†é¢‘ï¼ŒéªŒè¯ runner çš„å·¥ä½œæ–¹å¼ã€‚
    """
    videos_dir = ensure_videos_dir(job_dir)
    out_path = videos_dir / f"{shot['shot_id']}.mp4"

    src_video = job_dir / "input.mp4"
    if not src_video.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æºè§†é¢‘ï¼š{src_video}")

    ffmpeg = "/opt/homebrew/bin/ffmpeg"
    cmd = [
        ffmpeg, "-y",
        "-i", str(src_video),
        "-t", "1.0",
        "-c", "copy",
        str(out_path)
    ]
    subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    return f"videos/{out_path.name}"


def veo_generate_video(job_dir: Path, wf: dict, shot: dict) -> str:
    """
    Veo 3.1 å›¾ç”Ÿè§†é¢‘ï¼ˆå®˜æ–¹å†™æ³•ï¼štypes.Image.from_fileï¼‰
    - stylized_frame ä½œä¸º opening frame
    - å…ˆåšæœ€å°éªŒè¯ï¼š5 ç§’ã€1 ä¸ªè§†é¢‘
    """
    import os
    from google import genai
    from google.genai import types

    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise RuntimeError("æ²¡æœ‰æ£€æµ‹åˆ° GEMINI_API_KEY çŽ¯å¢ƒå˜é‡")

    videos_dir = ensure_videos_dir(job_dir)
    out_path = videos_dir / f"{shot['shot_id']}.mp4"

    img_rel = shot.get("assets", {}).get("stylized_frame")
    if not img_rel:
        raise RuntimeError("shot ç¼ºå°‘ assets.stylized_frame")
    img_path = job_dir / img_rel
    if not img_path.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° stylized_frameï¼š{img_path}")

    global_style = wf.get("global", {}).get("style_prompt", "")
    desc = shot.get("description", "")

    prompt = (
        "Use the reference image as the opening frame of the video, fully retaining its visual texture.\n"
        f"Scene: {desc}\n"
        f"Style: {global_style}\n"
        "Camera: slow cinematic push-in.\n"
    )

    # å…³é”®ï¼šç”¨å®˜æ–¹æŽ¨èçš„æ–¹å¼è¯»å–æœ¬åœ°å›¾ç‰‡ï¼ˆä¼šè‡ªåŠ¨æŽ¨æ–­ mimeTypeï¼‰
    image = types.Image.from_bytes(
    data=img_path.read_bytes(),
    mime_type="image/png",
)


    client = genai.Client(api_key=api_key)

    operation = client.models.generate_videos(
        model="veo-3.1-generate-preview",
        prompt=prompt,
        image=image,
        config=types.GenerateVideosConfig(
            number_of_videos=1,
            duration_seconds=5,
            enhance_prompt=True,
        ),
    )

    # è½®è¯¢ operationï¼ˆå®˜æ–¹ç¤ºä¾‹å†™æ³•ï¼‰
    while not getattr(operation, "done", False):
        time.sleep(20)
        operation = client.operations.get(operation)  # :contentReference[oaicite:2]{index=2}

    resp = getattr(operation, "response", None)
    if not resp or not getattr(resp, "generated_videos", None):
        raise RuntimeError(f"Veo è¿”å›žä¸ºç©ºï¼š{operation}")

    video = resp.generated_videos[0].video

    # å°½é‡ä¿å­˜åˆ°æœ¬åœ°ï¼šä¸åŒç‰ˆæœ¬ SDK video å¯¹è±¡æŽ¥å£å¯èƒ½ç•¥æœ‰å·®å¼‚
    if hasattr(video, "save"):
        video.save(str(out_path))
    else:
        # å…œåº•ï¼šè‡³å°‘æŠŠå¯¹è±¡è¿”å›žä¿¡æ¯æ‰“å°å‡ºæ¥ï¼Œé¿å…ä½ â€œå•¥ä¹Ÿæ²¡æ‹¿åˆ°â€
        raise RuntimeError(f"SDK è¿”å›ž video å¯¹è±¡ä¸æ”¯æŒ save(): {video}")

    return f"videos/{out_path.name}"


def run_stylize(job_dir: Path, wf: dict, target_shot: str | None = None) -> None:
    for shot in wf.get("shots", []):
        sid = shot.get("shot_id")
        if target_shot and sid != target_shot:
            continue

        status = shot.get("status", {}).get("stylize", "NOT_STARTED")
        if not target_shot and status not in ("NOT_STARTED", "FAILED"):
            continue

        shot.setdefault("status", {})["stylize"] = "RUNNING"
        shot.setdefault("errors", {})["stylize"] = None
        save_workflow(job_dir, wf)

        try:
            rel_path = mock_stylize_frame(job_dir, shot)
            shot.setdefault("assets", {})["stylized_frame"] = rel_path
            shot["status"]["stylize"] = "SUCCESS"
            print(f"âœ… stylize SUCCESS: {sid} -> {rel_path}")
        except Exception as e:
            shot["status"]["stylize"] = "FAILED"
            shot.setdefault("errors", {})["stylize"] = str(e)
            print(f"âŒ stylize FAILED: {sid} -> {e}")

        save_workflow(job_dir, wf)


def run_video_generate(job_dir: Path, wf: dict, target_shot: str | None = None) -> None:
    for shot in wf.get("shots", []):
        sid = shot.get("shot_id")
        if target_shot and sid != target_shot:
            continue

        status = shot.get("status", {}).get("video_generate", "NOT_STARTED")
        if not target_shot and status not in ("NOT_STARTED", "FAILED"):
            continue

        shot.setdefault("status", {})["video_generate"] = "RUNNING"
        shot.setdefault("errors", {})["video_generate"] = None
        save_workflow(job_dir, wf)

        try:
            video_model = wf.get("global", {}).get("video_model", "mock")

            if video_model == "veo":
                print("ðŸ”¥ USING VEO PATH")
                rel_video_path = veo_generate_video(job_dir, wf, shot)
            else:
                rel_video_path = mock_generate_video(job_dir, shot)

            shot.setdefault("assets", {})["video"] = rel_video_path
            shot["status"]["video_generate"] = "SUCCESS"
            print(f"âœ… video_generate SUCCESS: {sid} -> {rel_video_path}")
        except Exception as e:
            shot["status"]["video_generate"] = "FAILED"
            shot.setdefault("errors", {})["video_generate"] = str(e)
            print(f"âŒ video_generate FAILED: {sid} -> {e}")

        save_workflow(job_dir, wf)


def run_pipeline(job_dir: Path, target_shot: str | None = None) -> None:
    wf = load_workflow(job_dir)
    run_stylize(job_dir, wf, target_shot=target_shot)
    wf = load_workflow(job_dir)
    run_video_generate(job_dir, wf, target_shot=target_shot)



