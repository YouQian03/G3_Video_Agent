# core/workflow_manager.py
import json
import time
import os
import re
import uuid
import subprocess
import shutil
from pathlib import Path
from typing import Dict, List, Any, Optional, Union

from core.workflow_io import load_workflow, save_workflow
from core.changes import apply_global_style, replace_entity_reference
from core.runner import run_pipeline, run_stylize, run_video_generate

# å¼•å…¥æ‹†è§£æ‰€éœ€çš„åº“å’Œé€»è¾‘
from google import genai
from analyze_video import DIRECTOR_METAPROMPT, wait_until_file_active, extract_json_array
from extract_frames import to_seconds

class WorkflowManager:
    def __init__(self, job_id: Optional[str] = None, project_root: Optional[Path] = None):
        self.project_dir = project_root or Path(__file__).parent.parent
        self.job_id = job_id
        self.workflow: Dict[str, Any] = {}
        
        if job_id:
            self.job_dir = self.project_dir / "jobs" / job_id
            if (self.job_dir / "workflow.json").exists():
                self.load()

    def initialize_from_file(self, temp_video_path: Path) -> str:
        """å…¨è‡ªåŠ¨åˆå§‹åŒ–ç®¡çº¿ï¼šå®Œæˆæ‹†è§£ä¸åŸå§‹ç´ ææå–"""
        new_id = f"job_{uuid.uuid4().hex[:8]}"
        self.job_id = new_id
        self.job_dir = self.project_dir / "jobs" / new_id
        
        self.job_dir.mkdir(parents=True, exist_ok=True)
        (self.job_dir / "frames").mkdir(exist_ok=True)
        (self.job_dir / "videos").mkdir(exist_ok=True)
        (self.job_dir / "source_segments").mkdir(exist_ok=True)
        (self.job_dir / "stylized_frames").mkdir(exist_ok=True)
        
        final_video_path = self.job_dir / "input.mp4"
        shutil.move(str(temp_video_path), str(final_video_path))
        
        print(f"ğŸš€ [Phase 1] æ­£åœ¨é€šè¿‡ Gemini æ‹†è§£è§†é¢‘: {new_id}...")
        storyboard = self._run_gemini_analysis(final_video_path)
        
        print(f"ğŸš€ [Phase 2] æ­£åœ¨æå–å…³é”®å¸§ä¸åŸå§‹åˆ†é•œçŸ­ç‰‡...")
        self._run_ffmpeg_extraction(final_video_path, storyboard)
        
        shots = []
        for s in storyboard:
            shot_num = int(s.get("shot_number", 1))
            sid = f"shot_{shot_num:02d}"
            shots.append({
                "shot_id": sid,
                "start_time": s.get("start_time"),
                "end_time": s.get("end_time"),
                "description": s.get("frame_description") or s.get("content_analysis"),
                "entities": [],
                "assets": {
                    "first_frame": f"frames/{sid}.png",
                    "source_video_segment": f"source_segments/{sid}.mp4",
                    "stylized_frame": None, # ğŸ’¡ PMé€»è¾‘ï¼šåˆå§‹åŒ–ä¸ºç©ºï¼Œå¼ºåˆ¶è§¦å‘ AI ç”Ÿå›¾æµç¨‹
                    "video": None
                },
                "status": {
                    "stylize": "NOT_STARTED",
                    "video_generate": "NOT_STARTED"
                }
            })
            
        self.workflow = {
            "job_id": new_id,
            "source_video": "input.mp4",
            "global": {"style_prompt": "Cinematic Realistic", "video_model": "veo"},
            "global_stages": {
                "analyze": "SUCCESS", "extract": "SUCCESS", 
                "stylize": "NOT_STARTED", "video_gen": "NOT_STARTED", "merge": "NOT_STARTED"
            },
            "shots": shots,
            "meta": {"attempts": 0, "updated_at": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())}
        }
        
        self.save()
        print(f"âœ… [Done] è§†é¢‘æ‹†è§£ä¸åˆ‡ç‰‡å®Œæˆï¼ŒJob ID: {new_id}")
        return new_id

    def _run_gemini_analysis(self, video_path: Path):
        api_key = os.getenv("GEMINI_API_KEY")
        client = genai.Client(api_key=api_key)
        uploaded = client.files.upload(file=str(video_path))
        video_file = wait_until_file_active(client, uploaded)
        response = client.models.generate_content(
            model="gemini-2.0-flash",
            contents=[DIRECTOR_METAPROMPT, video_file],
        )
        raw_shots = extract_json_array(response.text)

        # è¯­ä¹‰åŒ–åˆå¹¶ï¼šå‡å°‘è¿‡åº¦åˆ†é•œ
        merged_shots = self._merge_semantic_shots(raw_shots, client)
        return merged_shots

    def _merge_semantic_shots(self, shots: List[Dict], client) -> List[Dict]:
        """
        è¯­ä¹‰åŒ–åˆå¹¶ï¼šå°†è¿ç»­çš„ã€èƒŒæ™¯/è§’åº¦/ä¸»ä½“ç›¸ä¼¼çš„åˆ†é•œåˆå¹¶ä¸ºä¸€ä¸ªå®Œæ•´åˆ†é•œã€‚
        ä½¿ç”¨ AI åˆ¤æ–­å“ªäº›è¿ç»­åˆ†é•œåº”è¯¥åˆå¹¶ã€‚
        """
        if len(shots) <= 1:
            return shots

        # æ„å»ºåˆå¹¶åˆ¤æ–­æç¤º
        shots_summary = []
        for i, s in enumerate(shots):
            shots_summary.append({
                "index": i,
                "start_time": s.get("start_time"),
                "end_time": s.get("end_time"),
                "description": s.get("frame_description") or s.get("content_analysis"),
                "shot_type": s.get("shot_type"),
                "camera_angle": s.get("camera_angle"),
                "camera_movement": s.get("camera_movement")
            })

        merge_prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å½±è§†å‰ªè¾‘å¸ˆã€‚è¯·åˆ†æä»¥ä¸‹åˆ†é•œåˆ—è¡¨ï¼Œåˆ¤æ–­å“ªäº›**è¿ç»­çš„**åˆ†é•œåº”è¯¥åˆå¹¶ã€‚

åˆå¹¶æ¡ä»¶ï¼ˆå¿…é¡»åŒæ—¶æ»¡è¶³ï¼‰ï¼š
1. åˆ†é•œæ˜¯**è¿ç»­çš„**ï¼ˆindex ç›¸é‚»ï¼‰
2. åœºæ™¯/èƒŒæ™¯æ²¡æœ‰æ˜¾è‘—å˜åŒ–
3. ä¸»ä½“/è§’è‰²æ²¡æœ‰åˆ‡æ¢
4. æœºä½è§’åº¦æ²¡æœ‰æ˜æ˜¾å˜åŒ–
5. å±äºåŒä¸€ä¸ªå®Œæ•´åŠ¨ä½œæˆ–äº‹ä»¶

åˆ†é•œåˆ—è¡¨ï¼š
{json.dumps(shots_summary, ensure_ascii=False, indent=2)}

è¯·è¾“å‡ºéœ€è¦åˆå¹¶çš„åˆ†é•œç»„ï¼Œæ ¼å¼ä¸ºçº¯JSONæ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªéœ€è¦åˆå¹¶çš„indexæ•°ç»„ã€‚
ä¾‹å¦‚ï¼š[[0,1,2], [5,6]] è¡¨ç¤ºå°†0-1-2åˆå¹¶ä¸ºä¸€ä¸ªåˆ†é•œï¼Œ5-6åˆå¹¶ä¸ºä¸€ä¸ªåˆ†é•œã€‚
å¦‚æœæ²¡æœ‰éœ€è¦åˆå¹¶çš„ï¼Œè¾“å‡ºç©ºæ•°ç»„ []ã€‚
ä»…è¾“å‡ºçº¯JSONï¼Œä¸è¦ä»»ä½•è§£é‡Šã€‚"""

        try:
            merge_response = client.models.generate_content(
                model="gemini-2.0-flash",
                contents=[merge_prompt],
            )
            merge_text = merge_response.text.strip()

            # æå–JSONæ•°ç»„
            if merge_text.startswith("["):
                merge_groups = json.loads(merge_text)
            else:
                l = merge_text.find("[")
                r = merge_text.rfind("]")
                if l != -1 and r != -1:
                    merge_groups = json.loads(merge_text[l:r+1])
                else:
                    merge_groups = []

            if not merge_groups:
                print(f"ğŸ“Š è¯­ä¹‰åˆ†æï¼šæ— éœ€åˆå¹¶ï¼Œä¿ç•™ {len(shots)} ä¸ªåˆ†é•œ")
                return shots

            # æ‰§è¡Œåˆå¹¶
            merged_indices = set()
            for group in merge_groups:
                if isinstance(group, list) and len(group) > 1:
                    merged_indices.update(group[1:])  # é™¤äº†ç¬¬ä¸€ä¸ªï¼Œå…¶ä½™æ ‡è®°ä¸ºè¢«åˆå¹¶

            result = []
            i = 0
            new_shot_num = 1
            while i < len(shots):
                shot = shots[i].copy()

                # æ£€æŸ¥æ˜¯å¦æ˜¯åˆå¹¶ç»„çš„èµ·å§‹
                merge_group = None
                for group in merge_groups:
                    if isinstance(group, list) and len(group) > 1 and group[0] == i:
                        merge_group = group
                        break

                if merge_group:
                    # åˆå¹¶è¯¥ç»„çš„æ‰€æœ‰åˆ†é•œ
                    last_idx = merge_group[-1]
                    shot["end_time"] = shots[last_idx].get("end_time")

                    # åˆå¹¶æè¿°
                    descriptions = []
                    for idx in merge_group:
                        if idx < len(shots):
                            desc = shots[idx].get("frame_description") or shots[idx].get("content_analysis")
                            if desc and desc not in descriptions:
                                descriptions.append(desc)
                    shot["frame_description"] = " â†’ ".join(descriptions[:3])  # æœ€å¤šä¿ç•™3æ®µæè¿°
                    shot["content_analysis"] = shot["frame_description"]

                    print(f"ğŸ”— åˆå¹¶åˆ†é•œ {[s+1 for s in merge_group]} -> shot_{new_shot_num:02d}")
                    i = last_idx + 1
                else:
                    if i not in merged_indices:
                        i += 1
                    else:
                        i += 1
                        continue

                shot["shot_number"] = new_shot_num
                result.append(shot)
                new_shot_num += 1

            print(f"ğŸ“Š è¯­ä¹‰åˆå¹¶å®Œæˆï¼š{len(shots)} ä¸ªåˆ†é•œ -> {len(result)} ä¸ªåˆ†é•œ")
            return result

        except Exception as e:
            print(f"âš ï¸ è¯­ä¹‰åˆå¹¶åˆ†æå¤±è´¥ ({e})ï¼Œä¿ç•™åŸå§‹åˆ†é•œ")
            return shots

    def _run_ffmpeg_extraction(self, video_path: Path, storyboard: List):
        """
        æ¯«ç§’çº§ç²¾å‡†æå–ï¼š
        - å…³é”®å¸§æå–ï¼šä»åˆ†é•œä¸­ç‚¹æå–ï¼Œç¡®ä¿ç”»é¢ä¸æè¿°ä¸€è‡´
        - è§†é¢‘ç‰‡æ®µï¼šä½¿ç”¨ç²¾å‡†åˆ‡å‰²æ¨¡å¼
        """
        ffmpeg_path = "/opt/homebrew/bin/ffmpeg"
        for s in storyboard:
            ts = to_seconds(s.get("start_time"))
            end_ts = to_seconds(s.get("end_time"))
            duration = end_ts - ts
            sid = f"shot_{int(s['shot_number']):02d}"

            # ğŸ¯ å…³é”®å¸§æå–ï¼šä»åˆ†é•œçš„**ä¸­ç‚¹**æå–ï¼Œè€Œéèµ·å§‹ç‚¹
            # åŸå› ï¼šèµ·å§‹ç‚¹å¯èƒ½æ˜¯è½¬åœºç¬é—´ï¼Œä¸­ç‚¹æ‰æ˜¯è¯¥åˆ†é•œçš„ä»£è¡¨æ€§ç”»é¢
            mid_ts = ts + (duration / 2.0)
            img_out = self.job_dir / "frames" / f"{sid}.png"
            subprocess.run([
                ffmpeg_path, "-y",
                "-i", str(video_path),
                "-ss", str(mid_ts),       # ä»ä¸­ç‚¹æå–ï¼Œç¡®ä¿ç”»é¢ä¸æè¿°ä¸€è‡´
                "-frames:v", "1",
                "-q:v", "2",
                str(img_out)
            ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

            # ğŸ¯ ç²¾å‡†è§†é¢‘ç‰‡æ®µåˆ‡å‰²
            video_segment_out = self.job_dir / "source_segments" / f"{sid}.mp4"
            subprocess.run([
                ffmpeg_path, "-y",
                "-i", str(video_path),
                "-ss", str(ts),           # è§†é¢‘ç‰‡æ®µä»èµ·å§‹ç‚¹å¼€å§‹
                "-t", str(duration),
                "-c:v", "libx264",        # é‡æ–°ç¼–ç ä»¥ç¡®ä¿ç²¾å‡†åˆ‡å‰²
                "-c:a", "aac",
                "-avoid_negative_ts", "make_zero",
                str(video_segment_out)
            ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

    def load(self):
        """åŠ è½½çŠ¶æ€å¹¶å¯¹é½ç‰©ç†æ–‡ä»¶çŠ¶æ€"""
        self.workflow = load_workflow(self.job_dir)
        if "global_stages" not in self.workflow:
            self.workflow["global_stages"] = {"analyze": "SUCCESS", "extract": "SUCCESS", "stylize": "NOT_STARTED", "video_gen": "NOT_STARTED", "merge": "NOT_STARTED"}

        updated = False
        shots = self.workflow.get("shots", [])
        for shot in shots:
            sid = shot.get("shot_id")
            status_node = shot.get("status", {})
            
            # 1. é£æ ¼åŒ–å‚è€ƒå›¾ç‰©ç†å¯¹é½
            stylized_path = self.job_dir / "stylized_frames" / f"{sid}.png"
            if stylized_path.exists() and status_node.get("stylize") != "SUCCESS":
                status_node["stylize"] = "SUCCESS"
                shot["assets"]["stylized_frame"] = f"stylized_frames/{sid}.png"
                updated = True

            # 2. è§†é¢‘äº§ç‰©ç‰©ç†å¯¹é½
            video_output_path = self.job_dir / "videos" / f"{sid}.mp4"
            current_video_status = status_node.get("video_generate")
            if video_output_path.exists() and current_video_status != "SUCCESS":
                status_node["video_generate"] = "SUCCESS"
                shot.setdefault("assets", {})["video"] = f"videos/{sid}.mp4"
                updated = True
            elif not video_output_path.exists() and current_video_status == "SUCCESS":
                status_node["video_generate"] = "NOT_STARTED"
                shot.setdefault("assets", {})["video"] = None
                updated = True
        
        # ğŸ’¡ æ ¸å¿ƒæ–°å¢ï¼šè®¡ç®—åˆå¹¶å°±ç»ªçŠ¶æ€ç»Ÿè®¡
        failed_count = sum(1 for s in shots if s["status"].get("video_generate") == "FAILED")
        pending_count = sum(1 for s in shots if s["status"].get("video_generate") in ["NOT_STARTED", "RUNNING"])
        
        self.workflow["merge_info"] = {
            "can_merge": failed_count == 0 and pending_count == 0 and len(shots) > 0,
            "failed_count": failed_count,
            "pending_count": pending_count,
            "message": ""
        }
        
        if failed_count > 0:
            self.workflow["merge_info"]["message"] = f"âš ï¸ {failed_count} shots failed and cannot be assembled."
        elif pending_count > 0:
            self.workflow["merge_info"]["message"] = "â³ Waiting for the shot list to be generated..."
        elif len(shots) > 0:
            self.workflow["merge_info"]["message"] = "âœ… All shots are ready and can be assembled into the final film."
        
        if updated: self.save()
        return self.workflow

    def save(self):
        self.workflow.setdefault("meta", {})["updated_at"] = time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())
        save_workflow(self.job_dir, self.workflow)

    def apply_agent_action(self, action: Union[Dict, List]) -> Dict[str, Any]:
        """å¤„ç†ä¿®æ”¹æ„å›¾ï¼šå¼ºåˆ¶é‡ç½®åç»­æ‰€æœ‰ä¾èµ–èŠ‚ç‚¹"""
        actions = action if isinstance(action, list) else [action]
        total_affected = 0
        for act in actions:
            op = act.get("op")
            
            if op == "set_global_style":
                affected = apply_global_style(self.workflow, act.get("value"), cascade=True)
                if affected > 0:
                    for s in self.workflow.get("shots", []):
                        v_path = self.job_dir / "videos" / f"{s['shot_id']}.mp4"
                        if v_path.exists(): os.remove(v_path)
                        i_path = self.job_dir / "stylized_frames" / f"{s['shot_id']}.png"
                        if i_path.exists(): os.remove(i_path)
                        s["status"]["stylize"] = "NOT_STARTED"
                        s["status"]["video_generate"] = "NOT_STARTED"
                        s["assets"]["video"] = None
                        s["assets"]["stylized_frame"] = None
                total_affected += affected
                
            elif op == "global_subject_swap":
                old_subject = act.get("old_subject", "").lower()
                new_subject = act.get("new_subject", "").lower()
                if old_subject and new_subject:
                    for s in self.workflow.get("shots", []):
                        if old_subject in s["description"].lower():
                            s["description"] = re.sub(old_subject, new_subject, s["description"], flags=re.IGNORECASE)
                            s["status"]["stylize"] = "NOT_STARTED"
                            s["status"]["video_generate"] = "NOT_STARTED"
                            v_path = self.job_dir / "videos" / f"{s['shot_id']}.mp4"
                            if v_path.exists(): os.remove(v_path)
                            i_path = self.job_dir / "stylized_frames" / f"{s['shot_id']}.png"
                            if i_path.exists(): os.remove(i_path)
                            s["assets"]["video"] = None
                            s["assets"]["stylized_frame"] = None
                            total_affected += 1
                            
            elif op == "update_shot_params":
                sid = act.get("shot_id")
                for s in self.workflow.get("shots", []):
                    if s["shot_id"] == sid:
                        if "description" in act: s["description"] = act["description"]
                        s["status"]["stylize"] = "NOT_STARTED"
                        s["status"]["video_generate"] = "NOT_STARTED"
                        v_path = self.job_dir / "videos" / f"{sid}.mp4"
                        if v_path.exists(): os.remove(v_path)
                        i_path = self.job_dir / "stylized_frames" / f"{sid}.png"
                        if i_path.exists(): os.remove(i_path)
                        s["assets"]["video"] = None
                        s["assets"]["stylized_frame"] = None
                        total_affected += 1
                        break

            elif op == "enhance_shot_description":
                # ğŸ“ ç©ºé—´æ„ŸçŸ¥ + ğŸ¬ é£æ ¼å¼ºåŒ–ï¼šå¢å¼ºåˆ†é•œæè¿°
                sid = act.get("shot_id")
                spatial_info = act.get("spatial_info", "")
                style_boost = act.get("style_boost", "")
                for s in self.workflow.get("shots", []):
                    if s["shot_id"] == sid:
                        original_desc = s.get("description", "")
                        enhanced_parts = [original_desc]
                        if spatial_info:
                            enhanced_parts.append(f"[Spatial: {spatial_info}]")
                        if style_boost:
                            enhanced_parts.append(f"[Style: {style_boost}]")
                        s["description"] = " ".join(enhanced_parts)
                        s["status"]["stylize"] = "NOT_STARTED"
                        s["status"]["video_generate"] = "NOT_STARTED"
                        v_path = self.job_dir / "videos" / f"{sid}.mp4"
                        if v_path.exists(): os.remove(v_path)
                        i_path = self.job_dir / "stylized_frames" / f"{sid}.png"
                        if i_path.exists(): os.remove(i_path)
                        s["assets"]["video"] = None
                        s["assets"]["stylized_frame"] = None
                        total_affected += 1
                        print(f"ğŸ“ å¢å¼ºåˆ†é•œæè¿°: {sid} -> {s['description'][:80]}...")
                        break

        if total_affected > 0: self.save()
        return {"status": "success", "affected_shots": total_affected}

    def run_node(self, node_type: str, shot_id: Optional[str] = None):
        """é€»è¾‘ç¼–æ’å¼•æ“ã€‚ç¡®ä¿â€˜å…ˆæœ‰å›¾ï¼Œåæœ‰è§†é¢‘â€™ä¸”æ— æ­»é”"""
        self.workflow.setdefault("meta", {}).setdefault("attempts", 0)
        self.workflow["meta"]["attempts"] += 1
        
        target_shots = [s for s in self.workflow.get("shots", []) if not shot_id or s["shot_id"] == shot_id]

        if node_type == "video_generate":
            for s in target_shots:
                if s["status"].get("stylize") != "SUCCESS":
                    print(f"ğŸ”— [Dependency] åˆ†é•œ {s['shot_id']} ç¼ºå°‘å®šå¦†å›¾ï¼Œæ­£åœ¨å‰ç½®ç”Ÿæˆ...")
                    run_stylize(self.job_dir, self.workflow, target_shot=s["shot_id"])
                    i_file = self.job_dir / "stylized_frames" / f"{s['shot_id']}.png"
                    if i_file.exists(): 
                        s["status"]["stylize"] = "SUCCESS"
                        s["assets"]["stylized_frame"] = f"stylized_frames/{s['shot_id']}.png"

        stage_key = "video_gen" if node_type == "video_generate" else "stylize"
        self.workflow["global_stages"][stage_key] = "RUNNING"

        for s in target_shots:
            if node_type == "video_generate":
                v_file = self.job_dir / "videos" / f"{s['shot_id']}.mp4"
                if v_file.exists(): os.remove(v_file)
                s["status"]["video_generate"] = "NOT_STARTED" 
                s["assets"]["video"] = None
            elif node_type == "stylize":
                i_file = self.job_dir / "stylized_frames" / f"{s['shot_id']}.png"
                if i_file.exists(): os.remove(i_file)
                s["status"]["stylize"] = "NOT_STARTED" 
                s["assets"]["stylized_frame"] = None

        self.save()

        if node_type == "stylize": 
            run_stylize(self.job_dir, self.workflow, target_shot=shot_id)
        elif node_type == "video_generate": 
            run_video_generate(self.job_dir, self.workflow, target_shot=shot_id)
        
        self.load() 

    def _get_shot_by_id(self, shot_id: str) -> Optional[Dict]:
        for s in self.workflow.get("shots", []):
            if s.get("shot_id") == shot_id: return s
        return None

    def merge_videos(self) -> str:
        """æ‰§è¡Œæ— æŸåˆå¹¶"""
        ffmpeg_path = "/opt/homebrew/bin/ffmpeg"
        success_shots = [s for s in self.workflow.get("shots", []) if s["status"].get("video_generate") == "SUCCESS"]
        if not success_shots: raise RuntimeError("æ²¡æœ‰å¯åˆå¹¶çš„åˆ†é•œè§†é¢‘ã€‚")
        success_shots.sort(key=lambda x: x["shot_id"])
        concat_list_path = self.job_dir / "concat_list.txt"
        output_video_path = self.job_dir / "final_output.mp4"
        with open(concat_list_path, "w", encoding="utf-8") as f:
            for s in success_shots:
                v_rel_path = s["assets"].get("video")
                if v_rel_path:
                    abs_v_path = (self.job_dir / v_rel_path).absolute()
                    f.write(f"file '{abs_v_path}'\n")
        cmd = [ffmpeg_path, "-y", "-f", "concat", "-safe", "0", "-i", str(concat_list_path), "-c", "copy", str(output_video_path)]
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode != 0: raise RuntimeError(f"åˆå¹¶å¤±è´¥: {result.stderr}")
        if "global_stages" in self.workflow:
            self.workflow["global_stages"]["merge"] = "SUCCESS"
        self.save()
        return "final_output.mp4"