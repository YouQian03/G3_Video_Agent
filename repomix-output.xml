This file is a merged representation of a subset of the codebase, containing files not matching ignore patterns, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of a subset of the repository's contents that is considered the most important context.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching these patterns are excluded: **/*.mp4, **/*.png, **/*.jpg, **/*.zip, **/venv/**, **/.venv/**, **/__pycache__/**, **/.git/**, all_code.txt, repomix-output.xml
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
core/
  __init__.py
  agent_engine.py
  changes.py
  runner.py
  workflow_io.py
  workflow_manager.py
.gitignore
agent_demo.py
analyze_video.py
app.py
apply_changes.py
build_workflow.py
extract_frames.py
index.html
run_workflow.py
smoke_test_core.py
stylize_frames.py
test_gemini.py
test_v3.py
vibe_check.py
video_generator.py
workflow_cli.py
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="core/__init__.py">

</file>

<file path="core/changes.py">
from typing import Optional

def apply_global_style(wf: dict, new_style_prompt: str, cascade: bool = True) -> int:
    wf.setdefault("global", {})["style_prompt"] = new_style_prompt

    affected = 0
    if cascade:
        for shot in wf.get("shots", []):
            shot.setdefault("status", {})["stylize"] = "NOT_STARTED"
            shot.setdefault("status", {})["video_generate"] = "NOT_STARTED"
            affected += 1
    return affected

def replace_entity_reference(wf: dict, entity_id: str, new_ref_image: str) -> int:
    entities = wf.setdefault("entities", {})
    if entity_id not in entities:
        raise KeyError(f"entity ä¸å­˜åœ¨ï¼š{entity_id}")

    entities[entity_id]["reference_image"] = new_ref_image

    affected = 0
    for shot in wf.get("shots", []):
        shot_entities = shot.get("entities", [])
        if entity_id in shot_entities:
            shot.setdefault("status", {})["stylize"] = "NOT_STARTED"
            shot.setdefault("status", {})["video_generate"] = "NOT_STARTED"
            affected += 1
    return affected
</file>

<file path="core/workflow_io.py">
import json
from pathlib import Path

def load_workflow(job_dir: Path) -> dict:
    wf_path = job_dir / "workflow.json"
    return json.loads(wf_path.read_text(encoding="utf-8"))

def save_workflow(job_dir: Path, wf: dict) -> None:
    wf_path = job_dir / "workflow.json"
    wf_path.write_text(
        json.dumps(wf, ensure_ascii=False, indent=2),
        encoding="utf-8"
    )
</file>

<file path=".gitignore">
# å¿½ç•¥ Python è™šæ‹Ÿç¯å¢ƒ
venv/
.venv/
__pycache__/
*.pyc

# å¿½ç•¥æ•æ„Ÿä¿¡æ¯
.env

# å¿½ç•¥ç”Ÿæˆçš„å¤§å‹èµ„æºæ–‡ä»¶ï¼ˆåªä¼ ä»£ç ï¼Œä¸ä¼ ç´ æï¼‰
jobs/
downloads/
outputs/
frames/
stylized_frames/
all_code.txt
repomix-output.xml
</file>

<file path="agent_demo.py">
# agent_demo.py
import os
from core.workflow_manager import WorkflowManager
from core.agent_engine import AgentEngine

def main():
    # 1. åˆå§‹åŒ–
    manager = WorkflowManager("demo_job_001")
    agent = AgentEngine()
    
    print("--- AI çˆ†æ¬¾äºŒåˆ› Agent é©±åŠ¨æ¨¡å¼ ---")
    print("å½“å‰é£æ ¼:", manager.workflow.get("global", {}).get("style_prompt"))
    print("å½“å‰å®ä½“:", list(manager.workflow.get("entities", {}).keys()))
    print("-" * 30)
    
    while True:
        user_text = input("\nğŸ¤– æ‚¨æƒ³å¯¹è§†é¢‘åšä½•ä¿®æ”¹ï¼Ÿ(è¾“å…¥ 'exit' é€€å‡º): ")
        if user_text.lower() == 'exit':
            break
            
        # å‡†å¤‡å·¥ä½œæµæ‘˜è¦ï¼ˆå‘Šè¯‰ Gemini å½“å‰æœ‰ä»€ä¹ˆï¼Œå®ƒæ‰èƒ½æ”¹ï¼‰
        summary = f"Style: {manager.workflow.get('global', {}).get('style_prompt')}\n"
        summary += f"Entities: {json.dumps(manager.workflow.get('entities', {}), indent=2)}"
        
        print("ğŸ” Agent æ­£åœ¨æ€è€ƒ...")
        action = agent.get_action_from_text(user_text, summary)
        
        print(f"ğŸ¯ è§£ææŒ‡ä»¤: {action}")
        
        if action.get("op") != "none" and action.get("op") != "error":
            # æ‰§è¡Œä¿®æ”¹
            res = manager.apply_agent_action(action)
            print(f"âœ… æ‰§è¡ŒæˆåŠŸï¼å—å½±å“åˆ†é•œæ•°: {res['affected_shots']}")
            print(f"ğŸ”„ æ‰€æœ‰å—å½±å“çš„åˆ†é•œçŠ¶æ€å·²é‡ç½®ï¼Œå‡†å¤‡é‡æ–°ç”Ÿæˆã€‚")
        else:
            print(f"âš ï¸ æ— æ³•æ‰§è¡Œ: {action.get('reason')}")

if __name__ == "__main__":
    import json
    main()
</file>

<file path="analyze_video.py">
import os
import json
import time
from pathlib import Path
from google import genai

PROJECT_DIR = Path(__file__).parent
VIDEO_PATH = PROJECT_DIR / "downloads" / "input.mp4"
OUT_PATH = PROJECT_DIR / "outputs" / "storyboard.json"

DIRECTOR_METAPROMPT = r"""
è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„å½±è§†åˆ†é•œåˆ†æå¸ˆï¼Œä¸“æ³¨ä»¥ã€Œç”»é¢å˜åŒ–ã€ä¸ºæ ¸å¿ƒï¼Œ
å°†åˆšæ‰çš„è§†é¢‘æ‹†è§£ä¸ºè¯¦ç»†çš„åˆ†é•œè¡¨ã€‚
ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡ºã€‚
æ ¹å…ƒç´ ä¸ºåŒ…å«å¤šä¸ªåˆ†é•œå¯¹è±¡çš„JSONæ•°ç»„ã€‚
æ¯ä¸ªå¯¹è±¡åŒ…å«ï¼š
shot_number, frame_description, content_analysis,
start_time, end_time, duration_seconds,
shot_type, camera_angle, camera_movement,
focus_and_depth, lighting, music_and_sound, voiceoverã€‚
æ— ä¿¡æ¯è¯·å¡« nullã€‚
ä»…è¾“å‡ºçº¯ JSONã€‚
""".strip()


def ensure_api_key() -> str:
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise RuntimeError(
            "æ²¡æœ‰æ£€æµ‹åˆ° GEMINI_API_KEY ç¯å¢ƒå˜é‡ã€‚\n"
            "è¯·åœ¨å½“å‰ç»ˆç«¯æ‰§è¡Œï¼š\n"
            '  export GEMINI_API_KEY="ä½ çš„key"\n'
            "ç„¶åå†è¿è¡Œæœ¬è„šæœ¬ã€‚"
        )
    return api_key


def extract_json_array(text: str):
    if not text:
        raise ValueError("æ¨¡å‹æ²¡æœ‰è¿”å›æ–‡æœ¬ï¼ˆresponse.text ä¸ºç©ºï¼‰ã€‚")

    s = text.strip()
    if s.startswith("[") and s.endswith("]"):
        return json.loads(s)

    l = s.find("[")
    r = s.rfind("]")
    if l != -1 and r != -1 and r > l:
        return json.loads(s[l : r + 1])

    raise ValueError(
        "æœªèƒ½ä»æ¨¡å‹è¾“å‡ºä¸­æå– JSON æ•°ç»„ã€‚\n"
        "è¯·æŠŠæ¨¡å‹åŸå§‹è¾“å‡ºå¤åˆ¶å‡ºæ¥æ£€æŸ¥ï¼ˆå®ƒå¯èƒ½æ²¡æœ‰æŒ‰è¦æ±‚è¾“å‡º JSONï¼‰ã€‚"
    )


def wait_until_file_active(client: genai.Client, file_obj, timeout_s: int = 120, poll_s: int = 2):
    """
    Files API ä¸Šä¼ åï¼Œæ–‡ä»¶å¯èƒ½å¤„äº PROCESSING çŠ¶æ€ï¼Œå¿…é¡»ç­‰åˆ° ACTIVE æ‰èƒ½ä½¿ç”¨ã€‚
    """
    file_name = getattr(file_obj, "name", None)
    if not file_name:
        # æå°‘æ•°æƒ…å†µä¸‹å¯¹è±¡ç»“æ„ä¸åŒï¼Œç›´æ¥è¿”å›è¯•è¯•
        return file_obj

    start = time.time()
    last_state = None

    while True:
        f = client.files.get(name=file_name)
        state = getattr(f, "state", None)

        if state != last_state:
            print(f"æ–‡ä»¶çŠ¶æ€ï¼š{state}")
            last_state = state

        if state == "ACTIVE":
            return f

        if time.time() - start > timeout_s:
            raise TimeoutError(
                f"ç­‰å¾…æ–‡ä»¶å˜ä¸º ACTIVE è¶…æ—¶ï¼ˆ>{timeout_s}sï¼‰ã€‚"
                "ä½ å¯ä»¥é‡è¯•ä¸€æ¬¡ï¼Œæˆ–è€…æ¢æ›´å°/æ›´å¸¸è§ç¼–ç çš„ mp4ã€‚"
            )

        time.sleep(poll_s)


def main():
    api_key = ensure_api_key()

    if not VIDEO_PATH.exists():
        raise FileNotFoundError(
            f"æ‰¾ä¸åˆ°è§†é¢‘æ–‡ä»¶ï¼š{VIDEO_PATH}\n"
            "è¯·ç¡®è®¤ä½ å·²æŠŠè§†é¢‘æ”¾åˆ° downloads/ é‡Œï¼Œå¹¶å‘½åä¸º input.mp4"
        )

    size_mb = VIDEO_PATH.stat().st_size / (1024 * 1024)
    print(f"å‡†å¤‡å¤„ç†è§†é¢‘ï¼š{VIDEO_PATH.name} ({size_mb:.1f} MB)")

    client = genai.Client(api_key=api_key)

    print("å¼€å§‹ä¸Šä¼ è§†é¢‘åˆ° Files APIâ€¦")
    uploaded = client.files.upload(file=str(VIDEO_PATH))
    print(f"âœ… ä¸Šä¼ å®Œæˆï¼š{uploaded.name}")

    print("ç­‰å¾…æ–‡ä»¶å˜ä¸º ACTIVEâ€¦")
    video_file = wait_until_file_active(client, uploaded, timeout_s=180, poll_s=2)
    print("âœ… æ–‡ä»¶å·² ACTIVEï¼Œå¯ä»¥å¼€å§‹åˆ†æ")

    print("å¼€å§‹åˆ†æè§†é¢‘ï¼ˆç”Ÿæˆåˆ†é•œ JSONï¼‰â€¦")
    response = client.models.generate_content(
        model="gemini-2.0-flash",
        contents=[DIRECTOR_METAPROMPT, video_file],
    )

    raw_text = getattr(response, "text", None) or ""
    storyboard = extract_json_array(raw_text)

    OUT_PATH.parent.mkdir(parents=True, exist_ok=True)
    OUT_PATH.write_text(
        json.dumps(storyboard, ensure_ascii=False, indent=2),
        encoding="utf-8",
    )

    print(f"\nâœ… å·²ç”Ÿæˆåˆ†é•œ JSONï¼š{OUT_PATH}")
    print(f"åˆ†é•œæ•°é‡ï¼š{len(storyboard)}")


if __name__ == "__main__":
    main()
</file>

<file path="apply_changes.py">
import json
import argparse
from pathlib import Path

PROJECT_DIR = Path(__file__).parent
DEFAULT_JOB_ID = "demo_job_001"

def load_workflow(job_dir: Path) -> dict:
    return json.loads((job_dir / "workflow.json").read_text(encoding="utf-8"))

def save_workflow(job_dir: Path, wf: dict) -> None:
    (job_dir / "workflow.json").write_text(json.dumps(wf, ensure_ascii=False, indent=2), encoding="utf-8")

def apply_global_style(wf: dict, new_style_prompt: str, cascade: bool = True) -> int:
    """
    ä¿®æ”¹å…¨å±€é£æ ¼ï¼Œå¹¶çº§è”ä½¿ç›¸å…³èŠ‚ç‚¹éœ€è¦é‡è·‘ã€‚
    cascade=Trueï¼šæŠŠæ‰€æœ‰ shots çš„ stylize & video_generate é‡ç½®ä¸º NOT_STARTED
    è¿”å›ï¼šå—å½±å“ shots æ•°é‡
    """
    wf.setdefault("global", {})["style_prompt"] = new_style_prompt

    affected = 0
    if cascade:
        for shot in wf.get("shots", []):
            # é£æ ¼æ”¹äº†ï¼Œé£æ ¼åŒ–å›¾å°±åº”è¯¥é‡æ–°ç”Ÿæˆï¼ˆçœŸå®äº§å“é‡Œå¯èƒ½æœ‰ç¼“å­˜ç­–ç•¥ï¼Œdemo å…ˆå…¨é‡è·‘ï¼‰
            shot.setdefault("status", {})["stylize"] = "NOT_STARTED"
            shot.setdefault("status", {})["video_generate"] = "NOT_STARTED"
            affected += 1
    return affected

def replace_entity_reference(wf: dict, entity_id: str, new_ref_image: str) -> int:
    """
    æ›¿æ¢æŸä¸ª entity çš„ reference_imageï¼Œå¹¶åªå½±å“å¼•ç”¨å®ƒçš„ shotsï¼š
    - æ ‡è®° stylize / video_generate ä¸º NOT_STARTED
    è¿”å›ï¼šå—å½±å“ shots æ•°é‡
    """
    entities = wf.setdefault("entities", {})
    if entity_id not in entities:
        raise KeyError(f"entity ä¸å­˜åœ¨ï¼š{entity_id}")

    entities[entity_id]["reference_image"] = new_ref_image

    affected = 0
    for shot in wf.get("shots", []):
        shot_entities = shot.get("entities", [])
        if entity_id in shot_entities:
            shot.setdefault("status", {})["stylize"] = "NOT_STARTED"
            shot.setdefault("status", {})["video_generate"] = "NOT_STARTED"
            affected += 1
    return affected


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--job_id", default=DEFAULT_JOB_ID)
    parser.add_argument("--set_global_style", default=None, help="è®¾ç½®æ–°çš„ global.style_prompt")
    parser.add_argument("--no_cascade", action="store_true", help="ä¸è§¦å‘çº§è”é‡è·‘ï¼ˆé»˜è®¤ä¼šè§¦å‘ï¼‰")
    parser.add_argument("--replace_entity", default=None, help="è¦æ›¿æ¢çš„ entity_idï¼Œä¾‹å¦‚ entity_1")
    parser.add_argument("--new_ref", default=None, help="æ–°çš„ reference_image è·¯å¾„ï¼Œä¾‹å¦‚ stylized_frames/shot_02.png")

    args = parser.parse_args()

    job_dir = PROJECT_DIR / "jobs" / args.job_id
    wf = load_workflow(job_dir)

    if args.set_global_style is not None:
        affected = apply_global_style(wf, args.set_global_style, cascade=(not args.no_cascade))
        save_workflow(job_dir, wf)
        print(f"âœ… å·²æ›´æ–° global.style_prompt")
        print(f"âœ… å—å½±å“ shotsï¼š{affected}ï¼ˆstylize/video_generate å·²æ ‡è®°ä¸º NOT_STARTEDï¼‰")
    else:
        print("æ²¡æœ‰æŒ‡å®šä»»ä½•ä¿®æ”¹å‚æ•°ã€‚ç¤ºä¾‹ï¼š")
        print('  python apply_changes.py --set_global_style "cinematic noir, high contrast"')
    
    if args.replace_entity and args.new_ref:
        affected = replace_entity_reference(wf, args.replace_entity, args.new_ref)
        save_workflow(job_dir, wf)
        print(f"âœ… å·²æ›¿æ¢ {args.replace_entity} çš„ reference_image -> {args.new_ref}")
        print(f"âœ… å—å½±å“ shotsï¼š{affected}ï¼ˆstylize/video_generate å·²æ ‡è®°ä¸º NOT_STARTEDï¼‰")
        return

if __name__ == "__main__":
    main()
</file>

<file path="build_workflow.py">
import json
from pathlib import Path

PROJECT_DIR = Path(__file__).parent
JOB_DIR = PROJECT_DIR / "jobs" / "demo_job_001"

STORYBOARD_PATH = JOB_DIR / "storyboard.json"
FRAMES_DIR = JOB_DIR / "frames"
STYLIZED_DIR = JOB_DIR / "stylized_frames"
WORKFLOW_PATH = JOB_DIR / "workflow.json"

def to_seconds(t):
    if t is None:
        return None
    if isinstance(t, (int, float)):
        return float(t)
    s = str(t).strip()
    if not s:
        return None
    try:
        return float(s)
    except ValueError:
        pass
    parts = s.split(":")
    try:
        parts = [float(p) for p in parts]
    except ValueError:
        return None
    if len(parts) == 3:
        hh, mm, ss = parts
        return hh * 3600 + mm * 60 + ss
    if len(parts) == 2:
        mm, ss = parts
        return mm * 60 + ss
    if len(parts) == 1:
        return parts[0]
    return None

def main():
    storyboard = json.loads(STORYBOARD_PATH.read_text(encoding="utf-8"))

    shots = []
    for s in storyboard:
        shot_number = s.get("shot_number")
        if shot_number is None:
            continue
        sid = f"shot_{int(shot_number):02d}"

        start = to_seconds(s.get("start_time"))
        end = to_seconds(s.get("end_time"))
        desc = s.get("frame_description") or s.get("content_analysis") or ""

        frame_path = f"frames/{sid}.png"
        stylized_path = f"stylized_frames/{sid}.png"

        shots.append({
            "shot_id": sid,
            "start_time": start,
            "end_time": end,
            "description": desc,
            "voiceover": s.get("voiceover"),
            "assets": {
                "first_frame": frame_path if (JOB_DIR / frame_path).exists() else None,
                "stylized_frame": stylized_path if (JOB_DIR / stylized_path).exists() else None,
                "video": None
            },
            "status": {
                "analyze": "SUCCESS",
                "extract_frames": "SUCCESS",
                "stylize": "SUCCESS",
                "video_generate": "NOT_STARTED"
            }
        })

    workflow = {
        "job_id": "demo_job_001",
        "source_video": "input.mp4",
        "global": {
            "aspect_ratio": "16:9",
            "style_prompt": "de-replication stylization"
        },
        "entities": {},  # å…ˆç•™ç©ºï¼Œåç»­æˆ‘ä»¬åŠ â€œäººç‰©/èµ„äº§å…¨å±€æ›¿æ¢â€
        "shots": shots
    }

    WORKFLOW_PATH.write_text(json.dumps(workflow, ensure_ascii=False, indent=2), encoding="utf-8")
    print(f"âœ… workflow.json å·²ç”Ÿæˆï¼š{WORKFLOW_PATH}")
    print(f"shots æ•°é‡ï¼š{len(shots)}")

if __name__ == "__main__":
    main()
</file>

<file path="extract_frames.py">
import json
import subprocess
from pathlib import Path

PROJECT_DIR = Path(__file__).parent
VIDEO_PATH = PROJECT_DIR / "downloads" / "input.mp4"
STORYBOARD_PATH = PROJECT_DIR / "outputs" / "storyboard.json"
FRAMES_DIR = PROJECT_DIR / "frames"

def to_seconds(t):
    if t is None:
        return None
    if isinstance(t, (int, float)):
        return float(t)

    s = str(t).strip()
    if not s:
        return None

    try:
        return float(s)
    except ValueError:
        pass

    parts = s.split(":")
    try:
        parts = [float(p) for p in parts]
    except ValueError:
        return None

    if len(parts) == 3:
        hh, mm, ss = parts
        return hh * 3600 + mm * 60 + ss
    if len(parts) == 2:
        mm, ss = parts
        return mm * 60 + ss
    if len(parts) == 1:
        return parts[0]
    return None

def main():
    if not VIDEO_PATH.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°è§†é¢‘ï¼š{VIDEO_PATH}")
    if not STORYBOARD_PATH.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° storyboardï¼š{STORYBOARD_PATH}")

    FRAMES_DIR.mkdir(parents=True, exist_ok=True)

    storyboard = json.loads(STORYBOARD_PATH.read_text(encoding="utf-8"))
    saved = 0

    for shot in storyboard:
        shot_num = shot.get("shot_number", saved + 1)
        start_time = shot.get("start_time", None)
        ts = to_seconds(start_time)

        if ts is None:
            continue

        out_path = FRAMES_DIR / f"shot_{int(shot_num):02d}.png"

        cmd = [
            "/opt/homebrew/bin/ffmpeg",
            "-y",
            "-ss", str(ts),
            "-i", str(VIDEO_PATH),
            "-frames:v", "1",
            "-q:v", "2",
            str(out_path)
        ]

        subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        if out_path.exists():
            saved += 1

    print(f"âœ… æˆªå¸§å®Œæˆï¼š{saved} å¼ ï¼Œä¿å­˜åœ¨ {FRAMES_DIR}")

if __name__ == "__main__":
    main()
</file>

<file path="run_workflow.py">
import json
import argparse
from pathlib import Path
import shutil

PROJECT_DIR = Path(__file__).parent
DEFAULT_JOB_ID = "demo_job_001"

def load_workflow(job_dir: Path) -> dict:
    wf_path = job_dir / "workflow.json"
    return json.loads(wf_path.read_text(encoding="utf-8"))

def save_workflow(job_dir: Path, wf: dict) -> None:
    wf_path = job_dir / "workflow.json"
    wf_path.write_text(json.dumps(wf, ensure_ascii=False, indent=2), encoding="utf-8")

def find_shot(wf: dict, shot_id: str) -> dict | None:
    for s in wf.get("shots", []):
        if s.get("shot_id") == shot_id:
            return s
    return None

def ensure_videos_dir(job_dir: Path) -> Path:
    videos_dir = job_dir / "videos"
    videos_dir.mkdir(parents=True, exist_ok=True)
    return videos_dir

def mock_generate_video(job_dir: Path, shot: dict) -> str:
    """
    Demo ç‰ˆæœ¬ï¼šç”Ÿæˆä¸€ä¸ªâ€œå ä½è§†é¢‘æ–‡ä»¶â€ï¼Œç”¨æ¥éªŒè¯ runner çš„å·¥ä½œæ–¹å¼ã€‚
    åç»­æ¥ Seedance/Veo æ—¶ï¼Œåªéœ€æ›¿æ¢è¿™ä¸ªå‡½æ•°ã€‚
    """
    videos_dir = ensure_videos_dir(job_dir)
    out_path = videos_dir / f"{shot['shot_id']}.mp4"

    # ç”¨ input.mp4 çš„å‰ 1 ç§’å¤åˆ¶æˆä¸€ä¸ªå°æ–‡ä»¶ï¼ˆç¡®ä¿æ˜¯å¯æ’­æ”¾ mp4ï¼‰
    src_video = job_dir / "input.mp4"
    if not src_video.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æºè§†é¢‘ï¼š{src_video}")

    # ç›´æ¥å¤åˆ¶ä¼šå¾ˆå¤§ï¼›ä¸ºäº†å¿«ï¼Œæˆ‘ä»¬å¤åˆ¶ä¸€ä¸ªå°ç‰‡æ®µï¼ˆç”¨ ffmpegï¼‰
    # ä½ å·²ç»å®‰è£…äº† ffmpegï¼Œä½† PATH å¯èƒ½ä¸ç¨³å®šï¼Œç”¨ç»å¯¹è·¯å¾„æœ€ç¨³
    ffmpeg = "/opt/homebrew/bin/ffmpeg"

    import subprocess
    cmd = [
        ffmpeg, "-y",
        "-i", str(src_video),
        "-t", "1.0",
        "-c", "copy",
        str(out_path)
    ]
    subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

    return f"videos/{out_path.name}"

def run_video_generate(job_dir: Path, wf: dict, target_shot: str | None = None) -> None:
    """
    æ‰§è¡Œ video_generate èŠ‚ç‚¹ï¼š
    - target_shot=Noneï¼šè·‘æ‰€æœ‰ NOT_STARTED æˆ– FAILED çš„ shot
    - target_shot=shot_03ï¼šåªè·‘æŒ‡å®š shotï¼ˆå•èŠ‚ç‚¹é‡è·‘ï¼‰
    """
    shots = wf.get("shots", [])
    for shot in shots:
        sid = shot.get("shot_id")

        if target_shot and sid != target_shot:
            continue

        status = shot.get("status", {}).get("video_generate", "NOT_STARTED")
        if not target_shot and status not in ("NOT_STARTED", "FAILED"):
            continue

        # æ ‡è®°è¿è¡Œä¸­
        shot.setdefault("status", {})["video_generate"] = "RUNNING"
        shot.setdefault("errors", {})["video_generate"] = None
        save_workflow(job_dir, wf)

        try:
            rel_video_path = mock_generate_video(job_dir, shot)
            shot.setdefault("assets", {})["video"] = rel_video_path
            shot["status"]["video_generate"] = "SUCCESS"
            print(f"âœ… video_generate SUCCESS: {sid} -> {rel_video_path}")
        except Exception as e:
            shot["status"]["video_generate"] = "FAILED"
            shot.setdefault("errors", {})["video_generate"] = str(e)
            print(f"âŒ video_generate FAILED: {sid} -> {e}")

        save_workflow(job_dir, wf)

def mock_stylize_frame(job_dir: Path, shot: dict) -> str:
    """
    Demo ç‰ˆé£æ ¼åŒ–ï¼šæŠŠ first_frame å¤åˆ¶æˆæ–°çš„ stylized_frameï¼ˆè¦†ç›–å†™ï¼‰ã€‚
    åç»­æ¥ Nano Banana æ—¶ï¼Œåªæ›¿æ¢è¿™é‡Œã€‚
    """
    src = job_dir / shot["assets"]["first_frame"]
    if not src.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° first_frameï¼š{src}")

    dst = job_dir / "stylized_frames" / f"{shot['shot_id']}.png"
    dst.parent.mkdir(parents=True, exist_ok=True)
    shutil.copyfile(src, dst)
    return f"stylized_frames/{dst.name}"

def run_stylize(job_dir: Path, wf: dict, target_shot: str | None = None) -> None:
    shots = wf.get("shots", [])
    for shot in shots:
        sid = shot.get("shot_id")

        if target_shot and sid != target_shot:
            continue

        status = shot.get("status", {}).get("stylize", "NOT_STARTED")
        if not target_shot and status not in ("NOT_STARTED", "FAILED"):
            continue

        shot.setdefault("status", {})["stylize"] = "RUNNING"
        shot.setdefault("errors", {})["stylize"] = None
        save_workflow(job_dir, wf)

        try:
            rel_path = mock_stylize_frame(job_dir, shot)
            shot.setdefault("assets", {})["stylized_frame"] = rel_path
            shot["status"]["stylize"] = "SUCCESS"
            print(f"âœ… stylize SUCCESS: {sid} -> {rel_path}")
        except Exception as e:
            shot["status"]["stylize"] = "FAILED"
            shot.setdefault("errors", {})["stylize"] = str(e)
            print(f"âŒ stylize FAILED: {sid} -> {e}")

        save_workflow(job_dir, wf)

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--job_id", default=DEFAULT_JOB_ID)
    parser.add_argument("--node", choices=["video_generate"], default="video_generate")
    parser.add_argument("--shot", default=None, help="åªè¿è¡ŒæŸä¸ª shotï¼Œä¾‹å¦‚ shot_03")
    args = parser.parse_args()

    job_dir = PROJECT_DIR / "jobs" / args.job_id
    if not job_dir.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° job ç›®å½•ï¼š{job_dir}")

    wf = load_workflow(job_dir)

    if args.node == "video_generate":
        # â‘  å…ˆè·‘ stylize èŠ‚ç‚¹
        run_stylize(job_dir, wf, target_shot=args.shot)

        # â‘¡ é‡æ–°åŠ è½½ workflowï¼ˆç¡®ä¿çŠ¶æ€æœ€æ–°ï¼‰
        wf = load_workflow(job_dir)

        # â‘¢ å†è·‘ video_generate èŠ‚ç‚¹
        run_video_generate(job_dir, wf, target_shot=args.shot)


    print("âœ… runner æ‰§è¡Œå®Œæˆ")

if __name__ == "__main__":
    main()
</file>

<file path="smoke_test_core.py">
from pathlib import Path
from core.workflow_io import load_workflow, save_workflow
from core.changes import replace_entity_reference
from core.runner import run_pipeline

JOB_DIR = Path("jobs/demo_job_001")

def main():
    wf = load_workflow(JOB_DIR)
    print("âœ… load_workflow ok, shots =", len(wf.get("shots", [])))

    # åšä¸€æ¬¡æ— å®³çš„ entity reference æ›¿æ¢ï¼ˆæ¢æˆè‡ªå·±å·²æœ‰çš„æ–‡ä»¶ï¼‰
    if "entity_1" in wf.get("entities", {}):
        replace_entity_reference(wf, "entity_1", "stylized_frames/shot_03.png")
        save_workflow(JOB_DIR, wf)
        print("âœ… replace_entity_reference ok")

    # è·‘ pipelineï¼ˆä¼šæŒ‰ NOT_STARTED æ‰§è¡Œï¼‰
    run_pipeline(JOB_DIR)
    print("âœ… run_pipeline ok")

if __name__ == "__main__":
    main()
</file>

<file path="stylize_frames.py">
import os
from pathlib import Path

from google import genai
from google.genai import types

PROJECT_DIR = Path(__file__).parent
FRAMES_DIR = PROJECT_DIR / "frames"
OUT_DIR = PROJECT_DIR / "stylized_frames"
OUT_DIR.mkdir(exist_ok=True)

MODEL = "gemini-2.5-flash-image"  # Nano Bananaï¼ˆæ›´å¿«ã€æ›´é€‚åˆéªŒè¯æ‰¹é‡ç¨³å®šæ€§ï¼‰
# å¦‚æœä½ ä¹‹åæƒ³ç”¨ Proï¼ˆæ›´å¼ºã€æ›´è´µï¼‰ï¼šMODEL = "gemini-3-pro-image-preview"

PROMPT = """
You are given a storyboard reference frame from a viral short video.

Goal: "De-replication stylization" (same structure, new details).
- Preserve: composition, camera angle, subject placement, overall color palette, lighting mood, and emotional tone.
- Must change: all fine details must be newly designed (faces, clothing details, textures, materials, patterns, background objects, any text/logos).
- Avoid pixel-level similarity. Do NOT copy any identifiable characters, logos, or exact text.
- Keep it cinematic and coherent.

Output:
- 16:9 image
- high clarity, rich details
"""

def save_first_image_from_response(response, out_path: Path) -> bool:
    """
    Nano Banana responses can include text parts and image parts.
    We scan parts and save the first image we find.
    """
    for part in response.parts:
        if part.inline_data is not None:
            img = part.as_image()   # requires pillow
            img.save(out_path)
            return True
    return False

def main():
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise RuntimeError("æ²¡æœ‰æ£€æµ‹åˆ° GEMINI_API_KEY ç¯å¢ƒå˜é‡ï¼ˆè¯·å…ˆ export GEMINI_API_KEY=ä½ çš„keyï¼‰")

    if not FRAMES_DIR.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° frames æ–‡ä»¶å¤¹ï¼š{FRAMES_DIR}")

    frame_paths = sorted(FRAMES_DIR.glob("shot_*.png"))
    if not frame_paths:
        raise FileNotFoundError(f"frames é‡Œæ²¡æœ‰ shot_*.pngï¼š{FRAMES_DIR}")

    client = genai.Client(api_key=api_key)

    print(f"å°†å¤„ç† {len(frame_paths)} å¼ åˆ†é•œå›¾ï¼Œè¾“å‡ºåˆ°ï¼š{OUT_DIR}")

    for img_path in frame_paths:
        out_path = OUT_DIR / img_path.name

        # ä¼ å…¥å›¾ç‰‡ï¼ˆå®˜æ–¹æ¨èï¼štypes.Part.from_bytesï¼‰
        image_part = types.Part.from_bytes(
            data=img_path.read_bytes(),
            mime_type="image/png",
        )

        print(f"ğŸ–¼ï¸  Stylize {img_path.name} ...")

        response = client.models.generate_content(
            model=MODEL,
            contents=[
                image_part,
                PROMPT
            ],
            # å¯é€‰ï¼šå¦‚æœä½ ç”¨ gemini-3-pro-image-preview æƒ³æŒ‡å®šè¾“å‡ºå‚æ•°ï¼Œå¯ä»¥æ‰“å¼€ä¸‹é¢ config
            # config=types.GenerateContentConfig(
            #     response_modalities=["TEXT", "IMAGE"],
            #     image_config=types.ImageConfig(aspect_ratio="16:9", image_size="2K"),
            # )
        )

        ok = save_first_image_from_response(response, out_path)
        if ok:
            print(f"âœ… saved -> {out_path}")
        else:
            # æœ‰æ—¶æ¨¡å‹åªå›æ–‡å­—ï¼ˆè¡¨ç¤ºæ²¡å‡ºå›¾æˆ–è¢«æ‹’ç»/é™çº§ï¼‰ï¼ŒæŠŠæ–‡å­—æ‰“å°å‡ºæ¥ä¾¿äºä½ åšå¯è¡Œæ€§åˆ¤æ–­
            print("âš ï¸ æ²¡æ‹¿åˆ°å›¾ç‰‡è¾“å‡ºï¼Œæ¨¡å‹è¿”å›æ–‡æœ¬å¦‚ä¸‹ï¼š")
            print(response.text)

    print("âœ… å…¨éƒ¨å®Œæˆ")

if __name__ == "__main__":
    main()
</file>

<file path="test_gemini.py">
import os
from google import genai

def main():
    # ä»ç¯å¢ƒå˜é‡ä¸­è¯»å– API Key
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise RuntimeError("æ²¡æœ‰æ£€æµ‹åˆ° GEMINI_API_KEY ç¯å¢ƒå˜é‡")

    client = genai.Client(api_key=api_key)

    response = client.models.generate_content(
        model="gemini-2.0-flash",
        contents="ç”¨ä¸€å¥è¯å‘Šè¯‰æˆ‘ï¼Œä½ æ˜¯è°ï¼Ÿ"
    )

    print("Gemini å›å¤ï¼š")
    print(response.text)

if __name__ == "__main__":
    main()
</file>

<file path="test_v3.py">
# test_v3.py
from core.workflow_manager import WorkflowManager

manager = WorkflowManager("demo_job_001")

# æµ‹è¯•å½¢æ€ 3ï¼šæ‰‹åŠ¨å¾®è°ƒç¬¬ 2 ä¸ªé•œå¤´çš„æè¿°
print("æµ‹è¯•å½¢æ€ 3ï¼šæ‰‹åŠ¨å¾®è°ƒåˆ†é•œ...")
manager.apply_agent_action({
    "op": "update_shot_params",
    "shot_id": "shot_02",
    "description": "ä¸€åªæ­£åœ¨æˆ´ç€å¢¨é•œè·³èˆçš„é…·ç‹—"
})

manager.load()
shot2 = [s for s in manager.workflow["shots"] if s["shot_id"] == "shot_02"][0]
print(f"åˆ†é•œ 2 æ–°æè¿°: {shot2['description']}")
print(f"åˆ†é•œ 2 çŠ¶æ€å·²é‡ç½®: {shot2['status']['video_generate']}") # åº”è¯¥æ˜¯ NOT_STARTED
print(f"å…¨å±€ Video Gen é˜¶æ®µçŠ¶æ€: {manager.workflow['global_stages']['video_gen']}")
</file>

<file path="vibe_check.py">
# vibe_check.py
from core.workflow_manager import WorkflowManager

# 1. åˆå§‹åŒ–ï¼ˆä½¿ç”¨ä½ å·²æœ‰çš„ demo_job_001ï¼‰
manager = WorkflowManager("demo_job_001")

# 2. æ¨¡æ‹Ÿå½¢æ€ 3ï¼šç›´æ¥æ”¹å…¨å±€é£æ ¼
print("æ­£åœ¨å°è¯•ä¿®æ”¹å…¨å±€é£æ ¼...")
res = manager.apply_agent_action({"op": "set_global_style", "value": "Cyberpunk Neon"})
print(f"å—å½±å“åˆ†é•œæ•°: {res['affected_shots']}")

# 3. éªŒè¯çŠ¶æ€æ˜¯å¦å˜å›äº† NOT_STARTED (è¿™æ˜¯æˆ‘ä»¬ changes.py é‡Œçš„çº§è”é€»è¾‘)
manager.load() # é‡æ–°åŠ è½½çœ‹ç£ç›˜ä¸Šçš„ç»“æœ
first_shot_status = manager.workflow["shots"][0]["status"]["video_generate"]
print(f"ä¿®æ”¹é£æ ¼åï¼ŒShot 01 çš„ç”ŸæˆçŠ¶æ€æ˜¯: {first_shot_status}")

if first_shot_status == "NOT_STARTED":
    print("âœ… åº•åº§é€»è¾‘éªŒè¯æˆåŠŸï¼")
else:
    print("âŒ çŠ¶æ€æ²¡æœ‰æ­£ç¡®é‡ç½®ï¼Œè¯·æ£€æŸ¥ core/changes.py")
</file>

<file path="video_generator.py">
import os
import time
from google import genai
from google.genai import types

# ç¡®ä¿ç¯å¢ƒå˜é‡å·²åŠ è½½
api_key = os.environ.get("GEMINI_API_KEY")
client = genai.Client(api_key=api_key)

def run_veo_generation(shot_id, prompt, image_path, output_dir="output_videos"):
    """
    é’ˆå¯¹ 2026 å¹´ Gemini 3 / Veo ç”Ÿæ€ä¼˜åŒ–çš„è§†é¢‘ç”Ÿæˆå‡½æ•°
    """
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # 1. ä»¥äºŒè¿›åˆ¶è¯»å–é£æ ¼åŒ–åçš„å‚è€ƒå›¾
    try:
        with open(image_path, 'rb') as f:
            image_bytes = f.read()
    except FileNotFoundError:
        print(f"âŒ æ‰¾ä¸åˆ°å›¾ç‰‡æ–‡ä»¶: {image_path}")
        return None

    print(f"ğŸš€ å¯åŠ¨ Veo 3.1 ä»»åŠ¡ | åˆ†é•œ: {shot_id}")
    
    try:
        # 2. è°ƒç”¨ä¸“é—¨çš„ generate_videos æ¥å£
        # ä¿®å¤ç‚¹ï¼šå¿…é¡»ä½¿ç”¨ generate_videos è€Œé generate_content
        operation = client.models.generate_videos(
            model="veo-3.1-generate-preview",
            prompt=prompt,
            config=types.GenerateVideosConfig(
                # ä¿®å¤ç‚¹ï¼šå‚è€ƒå›¾å¿…é¡»æ”¾åœ¨è¿™ä¸ª image å­—æ®µé‡Œ
                image=types.Part.from_bytes(
                    data=image_bytes,
                    mime_type="image/png"
                ),
                aspect_ratio="16:9"
            )
        )

        # 3. å¼‚æ­¥è½®è¯¢ (Veo è§†é¢‘ç”Ÿæˆä¸æ˜¯å³æ—¶çš„)
        print(f"â³ è§†é¢‘æ­£åœ¨äº‘ç«¯æ¸²æŸ“ (Operation ID: {operation.name})")
        while not operation.done:
            print(".", end="", flush=True)
            time.sleep(10)  # æ¯ 10 ç§’æŸ¥è¯¢ä¸€æ¬¡è¿›åº¦
            operation = client.operations.get(operation.name)

        # 4. æ£€æŸ¥ç»“æœå¹¶ä¿å­˜
        if operation.result and operation.result.generated_videos:
            generated_video = operation.result.generated_videos[0]
            output_path = os.path.join(output_dir, f"{shot_id}.mp4")
            
            # ä½¿ç”¨ SDK åŸç”Ÿ save æ–¹æ³•
            generated_video.video.save(output_path)
            print(f"\nâœ… è§†é¢‘ç”ŸæˆæˆåŠŸ: {output_path}")
            return output_path
        else:
            print(f"\nâŒ ç”Ÿæˆå¤±è´¥ï¼ŒåŸå› : {operation.error}")
            return None

    except Exception as e:
        print(f"\nâŒ è°ƒç”¨ Veo API å‡ºç°ä¸¥é‡å¼‚å¸¸: {str(e)}")
        return None

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç  (ä½ å¯ä»¥ç›´æ¥è¿è¡Œ python video_generator.py éªŒè¯)
    test_prompt = "A cinematic drone shot of a neon cyberpunk city in the rain."
    test_image = "stylized_frames/shot_01.png"
    run_veo_generation("shot_01", test_prompt, test_image)
</file>

<file path="workflow_cli.py">
import argparse
from pathlib import Path

from core.workflow_io import load_workflow, save_workflow
from core.changes import apply_global_style, replace_entity_reference
from core.runner import run_pipeline

DEFAULT_JOB_ID = "demo_job_001"
PROJECT_DIR = Path(__file__).parent

def job_dir_from_id(job_id: str) -> Path:
    return PROJECT_DIR / "jobs" / job_id

def cmd_list(job_dir: Path) -> None:
    wf = load_workflow(job_dir)
    print(f"job_id: {wf.get('job_id')}")
    print(f"global.style_prompt: {wf.get('global', {}).get('style_prompt')}")
    print("-" * 60)
    for s in wf.get("shots", []):
        sid = s.get("shot_id")
        st = s.get("status", {})
        print(f"{sid:7}  stylize={st.get('stylize')}  video={st.get('video_generate')}")

def cmd_set_style(job_dir: Path, style: str, cascade: bool) -> None:
    wf = load_workflow(job_dir)
    affected = apply_global_style(wf, style, cascade=cascade)
    save_workflow(job_dir, wf)
    print(f"âœ… style å·²æ›´æ–°ï¼š{style}")
    print(f"âœ… å—å½±å“ shotsï¼š{affected}ï¼ˆcascade={cascade}ï¼‰")

def cmd_replace_entity(job_dir: Path, entity_id: str, new_ref: str) -> None:
    wf = load_workflow(job_dir)
    affected = replace_entity_reference(wf, entity_id, new_ref)
    save_workflow(job_dir, wf)
    print(f"âœ… å·²æ›¿æ¢ {entity_id}.reference_image -> {new_ref}")
    print(f"âœ… å—å½±å“ shotsï¼š{affected}")

def cmd_run(job_dir: Path, shot: str | None) -> None:
    run_pipeline(job_dir, target_shot=shot)
    print("âœ… runner æ‰§è¡Œå®Œæˆ")

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--job_id", default=DEFAULT_JOB_ID)

    sub = parser.add_subparsers(dest="cmd", required=True)

    p_list = sub.add_parser("list", help="åˆ—å‡º shots çŠ¶æ€")
    p_list.set_defaults(func="list")

    p_style = sub.add_parser("set-style", help="è®¾ç½®å…¨å±€ style_prompt")
    p_style.add_argument("style")
    p_style.add_argument("--no-cascade", action="store_true", help="ä¸çº§è”é‡è·‘ï¼ˆé»˜è®¤ä¼šçº§è”ï¼‰")
    p_style.set_defaults(func="set-style")

    p_ent = sub.add_parser("replace-entity", help="æ›¿æ¢ entity çš„ reference_imageï¼Œå¹¶æ ‡è®°å—å½±å“ shots")
    p_ent.add_argument("entity_id")
    p_ent.add_argument("new_ref")
    p_ent.set_defaults(func="replace-entity")

    p_run = sub.add_parser("run", help="è¿è¡Œ runnerï¼ˆæŒ‰ NOT_STARTED æ‰§è¡Œï¼‰")
    p_run.add_argument("--shot", default=None, help="åªè·‘æŸä¸ª shotï¼Œä¾‹å¦‚ shot_03")
    p_run.set_defaults(func="run")

    args = parser.parse_args()
    job_dir = job_dir_from_id(args.job_id)
    if not job_dir.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° job ç›®å½•ï¼š{job_dir}")

    if args.func == "list":
        cmd_list(job_dir)
    elif args.func == "set-style":
        cmd_set_style(job_dir, args.style, cascade=(not args.no_cascade))
    elif args.func == "replace-entity":
        cmd_replace_entity(job_dir, args.entity_id, args.new_ref)
    elif args.func == "run":
        cmd_run(job_dir, args.shot)

if __name__ == "__main__":
    main()
</file>

<file path="core/agent_engine.py">
# core/agent_engine.py
import os
import json
import re
from google import genai
from google.genai import types # ğŸ’¡ å¼•å…¥ç±»å‹å®šä¹‰
from typing import Dict, Any, List, Union

class AgentEngine:
    def __init__(self):
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise RuntimeError("æœªæ£€æµ‹åˆ° GEMINI_API_KEY")
        self.client = genai.Client(api_key=api_key)
        self.model_id = "gemini-2.0-flash" 

    def get_action_from_text(self, user_input: str, workflow_summary: str) -> Union[Dict, List]:
        system_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘å¯¼æ¼”åŠ©ç†ã€‚ä½ å¿…é¡»æ ¹æ®ç”¨æˆ·éœ€æ±‚ç”Ÿæˆå·¥ä½œæµä¿®æ”¹æŒ‡ä»¤ã€‚

[å½“å‰çŠ¶æ€æ‘˜è¦]
{workflow_summary}

[æŒ‡ä»¤è§„èŒƒ]
1. ä¿®æ”¹å…¨å±€é£æ ¼: {{"op": "set_global_style", "value": "è‹±æ–‡é£æ ¼è¯"}}
2. æ›¿æ¢ä¸»ä½“åè¯: {{"op": "global_subject_swap", "old_subject": "è‹±æ–‡åŸè¯", "new_subject": "è‹±æ–‡æ–°è¯"}}
   - æ³¨æ„ï¼šä½ å¿…é¡»æ ¹æ®æ‘˜è¦è¯†åˆ«æè¿°ä¸­çš„è‹±æ–‡åŸè¯ï¼ˆå¦‚: dogï¼‰ï¼Œå¹¶ç¿»è¯‘ç”¨æˆ·çš„è¦æ±‚ï¼ˆå¦‚: ç‹—->dog, çŒ«->catï¼‰ã€‚

[è¾“å‡ºè¦æ±‚]
- å¿…é¡»è¯†åˆ«ç”¨æˆ·çš„æ‰€æœ‰æ„å›¾ã€‚
- å¿…é¡»è¿”å›ä¸€ä¸ªåŒ…å«æŒ‡ä»¤å¯¹è±¡çš„åˆ—è¡¨ []ã€‚
- ä¸¥ç¦è¾“å‡ºä»»ä½•è§£é‡Šæ€§æ–‡å­—ï¼Œåªè¾“å‡ºçº¯ JSONã€‚
"""
        try:
            # ğŸ’¡ æ ¸å¿ƒå‡çº§ï¼šå¼ºè¿«æ¨¡å‹è¾“å‡ºç¬¦åˆ JSON ç»“æ„çš„æ ¼å¼
            response = self.client.models.generate_content(
                model=self.model_id,
                contents=[system_prompt, f"ç”¨æˆ·æŒ‡ä»¤: {user_input}"],
                config=types.GenerateContentConfig(
                    response_mime_type='application/json', # ğŸ‘ˆ å¼ºåˆ¶ JSON æ¨¡å¼
                )
            )
            
            # ç›´æ¥è§£æï¼ŒJSON æ¨¡å¼ä¸‹æ¨¡å‹è¿”å›çš„ä¸€å®šæ˜¯åˆæ³•çš„ JSON å­—ç¬¦ä¸²
            res_json = json.loads(response.text)
            print(f"ğŸ¤– Agent å†³ç­–ç»“æœ: {res_json}")
            return res_json
            
        except Exception as e:
            # å¢åŠ æ›´è¯¦ç»†çš„é”™è¯¯æ‰“å°
            print(f"âŒ Agent è°ƒç”¨å‡ºç°å¼‚å¸¸: {str(e)}")
            if 'response' in locals() and hasattr(response, 'candidates'):
                print(f"ğŸ” è°ƒè¯•ä¿¡æ¯ - åœæ­¢åŸå› : {response.candidates[0].finish_reason}")
            return {"op": "error", "reason": str(e)}
</file>

<file path="app.py">
# app.py
import os
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from pydantic import BaseModel
from typing import Optional, Dict, Any, List, Union

from core.workflow_manager import WorkflowManager
from core.agent_engine import AgentEngine

app = FastAPI(title="AI å¯¼æ¼”å·¥ä½œå° API")

# 1. è·¨åŸŸé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# 2. åˆå§‹åŒ–æ ¸å¿ƒå¼•æ“
JOB_ID = "demo_job_001"
manager = WorkflowManager(JOB_ID)
agent = AgentEngine()

# --- æ•°æ®æ¨¡å‹ ---
class ChatRequest(BaseModel):
    message: str

class ShotUpdateRequest(BaseModel):
    shot_id: str
    description: Optional[str] = None
    video_model: Optional[str] = None

# --- è·¯ç”±æ¥å£ ---

@app.get("/")
async def read_index():
    """å…¥å£ï¼šè¿”å›ä¸»é¡µ"""
    return FileResponse('index.html')

@app.get("/api/workflow")
async def get_workflow():
    """å½¢æ€ 1 & 3 çš„æ•°æ®æºï¼šè·å–æœ€æ–°å…¨å±€çŠ¶æ€"""
    # æ¯æ¬¡è¯·æ±‚å¼ºåˆ¶ä»ç£ç›˜è¯»å–æœ€æ–°çŠ¶æ€ï¼Œç¡®ä¿å¤šè¿›ç¨‹é—´æ•°æ®å¯¹é½
    return manager.load()

@app.post("/api/agent/chat")
async def agent_chat(req: ChatRequest):
    """å½¢æ€ 2ï¼šAgent å…¨å±€æŒ‡æŒ¥ (æ”¯æŒå¤šæŒ‡ä»¤å’Œè‡ªåŠ¨ç¿»è¯‘æ›¿æ¢)"""
    wf = manager.load()
    
    # ğŸ’¡ æ ¸å¿ƒä¼˜åŒ–ï¼šæä¾›æ›´æ˜¾å¼çš„ä¸Šä¸‹æ–‡æ‘˜è¦
    # è®© Agent çœ‹åˆ° description çš„å®é™…å†…å®¹ï¼ˆé€šå¸¸æ˜¯è‹±æ–‡ï¼‰ï¼Œå®ƒæ‰çŸ¥é“å»æ›¿æ¢å“ªä¸ªè‹±æ–‡å•è¯
    example_desc = ""
    if wf.get("shots") and len(wf.get("shots")) > 0:
        example_desc = wf.get("shots")[0].get("description", "")
        
    summary = f"Global Style: {wf.get('global', {}).get('style_prompt')}\n"
    summary += f"Current Sample Description: {example_desc}\n" # ğŸ‘ˆ è®© Agent è¯†åˆ«åˆ° 'dog'
    summary += f"Entities: {list(wf.get('entities', {}).keys())}"
    
    # è·å– Agent çš„å†³ç­–ï¼ˆæ”¯æŒ JSON åˆ—è¡¨ï¼‰
    action = agent.get_action_from_text(req.message, summary)
    
    # ğŸ’¡ éªŒè¯æŒ‡ä»¤æœ‰æ•ˆæ€§
    is_valid = False
    if isinstance(action, list):
        is_valid = len(action) > 0
    elif isinstance(action, dict):
        is_valid = action.get("op") not in ["none", "error"]
        
    if is_valid:
        # æ‰§è¡Œä¿®æ”¹ï¼ˆWorkflowManager å·²æ”¯æŒå¤„ç† list æˆ– dictï¼‰
        res = manager.apply_agent_action(action)
        return {"action": action, "result": res}
    
    return {"action": action, "result": {"status": "ignored", "reason": "No valid action parsed or safety filter triggered"}}

@app.post("/api/shot/update")
async def update_shot_params(req: ShotUpdateRequest):
    """å½¢æ€ 3ï¼šæ‰‹åŠ¨å¾®è°ƒå•ä¸ªåˆ†é•œ (Higgsfield é£æ ¼)"""
    action = {
        "op": "update_shot_params",
        "shot_id": req.shot_id,
    }
    if req.description: action["description"] = req.description
    if req.video_model: action["video_model"] = req.video_model
    
    res = manager.apply_agent_action(action)
    return res

@app.post("/api/run/{node_type}")
async def run_task(node_type: str, background_tasks: BackgroundTasks, shot_id: Optional[str] = None):
    """å½¢æ€ 1 çš„æ‰§è¡Œå¼•æ“ï¼šæ”¯æŒå¼‚æ­¥è¿è¡Œä»»åŠ¡"""
    if node_type not in ["stylize", "video_generate"]:
        raise HTTPException(status_code=400, detail="æ— æ•ˆçš„èŠ‚ç‚¹ç±»å‹")
    
    # åœ¨åå°ä»»åŠ¡ä¸­å¯åŠ¨ï¼Œä¸é˜»å¡å‰ç«¯è¯·æ±‚
    background_tasks.add_task(manager.run_node, node_type, shot_id)
    return {"status": "started", "node": node_type, "shot_id": shot_id}

# --- æ ¸å¿ƒä¿®å¤ï¼šæ·»åŠ é˜²ç¼“å­˜ä¸­é—´ä»¶ ---
@app.middleware("http")
async def add_no_cache_header(request, call_next):
    response = await call_next(request)
    if request.url.path.startswith("/assets"):
        response.headers["Cache-Control"] = "no-store, no-cache, must-revalidate, max-age=0"
        response.headers["Pragma"] = "no-cache"
        response.headers["Expires"] = "0"
    return response

# 3. é™æ€èµ„æºæŒ‚è½½
app.mount("/assets", StaticFiles(directory=f"jobs/{JOB_ID}"), name="assets")

if __name__ == "__main__":
    import uvicorn
    # å¯åŠ¨å‘½ä»¤ï¼špython app.py
    uvicorn.run(app, host="0.0.0.0", port=8000)
</file>

<file path="core/workflow_manager.py">
# core/workflow_manager.py
import json
import time
import os
import re
from pathlib import Path
from typing import Dict, List, Any, Optional, Union

from core.workflow_io import load_workflow, save_workflow
from core.changes import apply_global_style, replace_entity_reference
from core.runner import run_pipeline, run_stylize, run_video_generate

class WorkflowManager:
    def __init__(self, job_id: str, project_root: Optional[Path] = None):
        self.job_id = job_id
        self.project_dir = project_root or Path(__file__).parent.parent
        self.job_dir = self.project_dir / "jobs" / job_id
        self.workflow: Dict[str, Any] = {}
        if (self.job_dir / "workflow.json").exists():
            self.load()

    def load(self):
        self.workflow = load_workflow(self.job_dir)
        if "global_stages" not in self.workflow:
            self.workflow["global_stages"] = {"analyze": "SUCCESS", "extract": "SUCCESS", "stylize": "NOT_STARTED", "video_gen": "NOT_STARTED", "merge": "NOT_STARTED"}
        
        updated = False
        for shot in self.workflow.get("shots", []):
            sid = shot.get("shot_id")
            video_output_path = self.job_dir / "videos" / f"{sid}.mp4"
            status_node = shot.get("status", {})
            if status_node.get("video_generate") == "RUNNING" and video_output_path.exists():
                status_node["video_generate"] = "SUCCESS"
                shot.setdefault("assets", {})["video"] = f"videos/{sid}.mp4"
                updated = True
        if updated: self.save()
        return self.workflow

    def save(self):
        self.workflow.setdefault("meta", {})["updated_at"] = time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())
        save_workflow(self.job_dir, self.workflow)

    def apply_agent_action(self, action: Union[Dict, List]) -> Dict[str, Any]:
        actions = action if isinstance(action, list) else [action]
        total_affected = 0
        print(f"ğŸ“¦ æ­£åœ¨å¤„ç† Agent æŒ‡ä»¤ï¼Œå…± {len(actions)} æ¡")

        for act in actions:
            op = act.get("op")
            print(f"âš™ï¸ æ‰§è¡Œæ“ä½œ: {op} | å‚æ•°: {act}")

            if op == "set_global_style":
                val = act.get("value")
                affected = apply_global_style(self.workflow, val, cascade=True)
                if affected > 0:
                    for s in self.workflow.get("shots", []): s.setdefault("assets", {})["video"] = None
                total_affected += affected
            
            elif op == "global_subject_swap":
                old_s = act.get("old_subject", "").lower()
                new_s = act.get("new_subject", "").lower()
                if old_s and new_s:
                    for s in self.workflow.get("shots", []):
                        if old_s in s["description"].lower():
                            s["description"] = re.sub(old_s, new_s, s["description"], flags=re.IGNORECASE)
                            s["status"]["video_generate"] = "NOT_STARTED"
                            s["assets"]["video"] = None
                            total_affected += 1
                print(f"ğŸ± æ›¿æ¢å®Œæˆï¼š{old_s} -> {new_s}ï¼Œå½±å“ {total_affected} å¤„")

            elif op == "update_shot_params":
                # å…¼å®¹æ‰‹åŠ¨ç²¾ä¿®
                sid = act.get("shot_id")
                for s in self.workflow.get("shots", []):
                    if s["shot_id"] == sid:
                        if "description" in act: s["description"] = act["description"]
                        s["status"]["video_generate"] = "NOT_STARTED"
                        s["assets"]["video"] = None
                        total_affected += 1

        if total_affected > 0:
            self.save()
        return {"status": "success", "affected_shots": total_affected}

    def run_node(self, node_type: str, shot_id: Optional[str] = None):
        self.workflow["global_stages"]["video_gen"] = "RUNNING"
        self.save()
        if node_type == "video_generate":
            shots = [s for s in self.workflow.get("shots", []) if not shot_id or s["shot_id"] == shot_id]
            for s in shots:
                p = self.job_dir / "videos" / f"{s['shot_id']}.mp4"
                if p.exists(): os.remove(p)
                s["status"]["video_generate"] = "RUNNING"
                s["assets"]["video"] = None
        self.save()
        if node_type == "stylize": run_stylize(self.job_dir, self.workflow, target_shot=shot_id)
        elif node_type == "video_generate": run_video_generate(self.job_dir, self.workflow, target_shot=shot_id)
        self.load()
</file>

<file path="index.html">
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI å¯¼æ¼”å·¥ä½œå° - å·¥ä¸šçº§æ”¾å°„æµ</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://unpkg.com/react@18/umd/react.development.js"></script>
    <script src="https://unpkg.com/react-dom@18/umd/react-dom.development.js"></script>
    <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;700&family=Inter:wght@400;600&display=swap');
        body { font-family: 'Inter', sans-serif; background-color: #020617; color: #f8fafc; }
        .glass { background: rgba(15, 23, 42, 0.8); backdrop-filter: blur(12px); border: 1px solid rgba(255,255,255,0.05); }
        
        /* ğŸ’¡ è¿çº¿æ ·å¼ */
        .node-line { stroke: #3b82f6; stroke-width: 1.5; fill: none; stroke-opacity: 0.15; transition: stroke-opacity 0.3s; }
        .node-line-active { stroke: #3b82f6; stroke-width: 2.5; stroke-dasharray: 6; animation: flow 1.5s linear infinite; stroke-opacity: 0.8; }
        @keyframes flow { from { stroke-dashoffset: 24; } to { stroke-dashoffset: 0; } }

        .custom-scrollbar::-webkit-scrollbar { width: 4px; }
        .custom-scrollbar::-webkit-scrollbar-thumb { background: #1e293b; border-radius: 10px; }
        
        /* å›ºå®šè¡Œé«˜ï¼Œç¡®ä¿è¿çº¿è®¡ç®—ç²¾å‡† */
        .shot-row-container { height: 220px; display: flex; align-items: center; }
    </style>
</head>
<body>
    <div id="root"></div>

    <script type="text/babel">
        const { useState, useEffect, useRef } = React;

        const App = () => {
            const [workflow, setWorkflow] = useState(null);
            const [viewMode, setViewMode] = useState('grid'); 
            const [messages, setMessages] = useState([{ role: 'ai', text: 'æˆ‘æ˜¯æ‚¨çš„ AI æŒ‡æŒ¥å®˜ã€‚å·¥ä½œæµå·²å°±ç»ªã€‚' }]);
            const [inputText, setInputText] = useState('');
            const [loading, setLoading] = useState(false);
            
            // ğŸ’¡ çŠ¶æ€åŒæ­¥å…³é”®ï¼šè®°å½•æ»šåŠ¨ä½ç½®å’Œå®¹å™¨é«˜åº¦
            const scrollRef = useRef(null);
            const [scrollTop, setScrollTop] = useState(0);
            const [containerHeight, setContainerHeight] = useState(0);

            const fetchWorkflow = async () => {
                const res = await fetch('/api/workflow');
                const data = await res.json();
                setWorkflow(data);
            };

            useEffect(() => {
                fetchWorkflow();
                const timer = setInterval(fetchWorkflow, 3000);
                return () => clearInterval(timer);
            }, []);

            // ğŸ’¡ å®æ—¶ç›‘å¬æ»šåŠ¨
            const onScroll = (e) => setScrollTop(e.target.scrollTop);

            // è·å–å®¹å™¨é«˜åº¦ç”¨äºè®¡ç®—å±…ä¸­èµ·ç‚¹
            useEffect(() => {
                if (viewMode === 'graph' && scrollRef.current) {
                    setContainerHeight(scrollRef.current.clientHeight);
                }
            }, [viewMode]);

            const sendAgentMsg = async () => {
                if (!inputText.trim()) return;
                const msg = inputText; setInputText('');
                setMessages(prev => [...prev, { role: 'user', text: msg }]);
                setLoading(true);
                await fetch('/api/agent/chat', { method: 'POST', headers: {'Content-Type': 'application/json'}, body: JSON.stringify({ message: msg }) });
                setLoading(false);
                fetchWorkflow();
            };

            const updateShot = async (shotId, desc) => {
                await fetch('/api/shot/update', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({ shot_id: shotId, description: desc })
                });
                fetchWorkflow();
            };

            const runTask = async (type, shotId = null) => {
                await fetch(`/api/run/${type}${shotId ? `?shot_id=${shotId}` : ''}`, { method: 'POST' });
            };

            if (!workflow) return <div className="h-screen flex items-center justify-center font-mono">INITIATING...</div>;

            return (
                <div className="h-screen flex flex-col p-4 gap-4 overflow-hidden">
                    {/* Header */}
                    <div className="glass rounded-2xl p-4 flex items-center justify-between border border-white/5">
                        <div className="flex items-center gap-6">
                            <h1 className="text-xl font-bold tracking-tight bg-gradient-to-r from-blue-400 to-emerald-400 bg-clip-text text-transparent">AI CONTENT WORKSTATION</h1>
                            <div className="flex bg-slate-900 rounded-xl p-1 border border-white/10 shadow-inner">
                                <button onClick={() => setViewMode('grid')} className={`px-5 py-1.5 rounded-lg text-xs font-bold transition ${viewMode === 'grid' ? 'bg-blue-600 text-white shadow-lg' : 'text-slate-500'}`}>STORYBOARD (å¯¹æ¯”)</button>
                                <button onClick={() => setViewMode('graph')} className={`px-5 py-1.5 rounded-lg text-xs font-bold transition ${viewMode === 'graph' ? 'bg-blue-600 text-white shadow-lg' : 'text-slate-500'}`}>LOGIC GRAPH (æ”¾å°„)</button>
                            </div>
                        </div>
                        <button onClick={() => runTask('video_generate')} className="bg-emerald-600 hover:bg-emerald-500 px-6 py-2 rounded-xl text-sm font-black shadow-lg transition-all active:scale-95">RUN WORKFLOW</button>
                    </div>

                    <div className="flex flex-1 gap-4 overflow-hidden">
                        <div className="flex-1 glass rounded-[2.5rem] overflow-hidden relative border border-white/10 shadow-2xl bg-slate-950">
                            
                            {/* --- è§†å›¾ Aï¼šStoryboard å¯¹æ¯” --- */}
                            {viewMode === 'grid' && (
                                <div className="h-full overflow-y-auto p-8 custom-scrollbar">
                                    <div className="grid grid-cols-1 xl:grid-cols-2 gap-8">
                                        {workflow.shots?.map(shot => {
                                            const isSuccess = shot.status?.video_generate === 'SUCCESS';
                                            return (
                                                <div key={shot.shot_id} className="glass rounded-3xl overflow-hidden border border-white/5 p-4 bg-slate-950/20">
                                                    <div className="flex justify-between items-center mb-3">
                                                        <span className="font-mono text-xs text-blue-400 font-bold uppercase tracking-widest">{shot.shot_id}</span>
                                                        <span className="text-[10px] text-slate-500">{shot.start_time}s - {shot.end_time}s</span>
                                                    </div>
                                                    <div className="grid grid-cols-2 gap-4">
                                                        <div className="relative aspect-video rounded-xl overflow-hidden border border-white/10">
                                                            <img src={`/assets/${shot.assets?.first_frame}`} className="w-full h-full object-cover" />
                                                            <div className="absolute top-2 right-2 bg-red-500 text-[8px] px-1.5 py-0.5 font-black rounded text-white">SOURCE</div>
                                                        </div>
                                                        <div className={`relative aspect-video rounded-xl overflow-hidden border ${isSuccess ? 'border-emerald-500/40' : 'border-blue-500/20'}`}>
                                                            {isSuccess && shot.assets?.video ? (
                                                                <video src={`/assets/${shot.assets.video}?t=${Date.now()}`} className="w-full h-full object-cover" controls autoPlay muted loop />
                                                            ) : (
                                                                <div className="flex h-full items-center justify-center bg-slate-900 font-mono text-[9px] text-blue-400 tracking-widest animate-pulse">{shot.status?.video_generate}</div>
                                                            )}
                                                            <div className="absolute top-2 right-2 bg-blue-500 text-[8px] px-1.5 py-0.5 font-black rounded text-white uppercase tracking-tighter">AI OUTPUT</div>
                                                        </div>
                                                    </div>
                                                    <div className="mt-4 p-3 bg-slate-900/50 rounded-2xl border border-white/5">
                                                        <textarea className="w-full bg-transparent border-none text-xs text-slate-300 outline-none h-14 resize-none leading-relaxed italic" defaultValue={shot.description} onBlur={(e) => updateShot(shot.shot_id, e.target.value)} />
                                                        <div className="flex justify-end mt-2"><button onClick={() => runTask('video_generate', shot.shot_id)} className="text-[9px] text-emerald-400 font-bold uppercase tracking-widest hover:text-emerald-300 transition-colors">Re-Generate</button></div>
                                                    </div>
                                                </div>
                                            );
                                        })}
                                    </div>
                                </div>
                            )}

                            {/* --- è§†å›¾ Bï¼šçœŸæ­£çš„æ”¾å°„æµå›¾ (å›ºå®šèµ·ç‚¹ + åŠ¨æ€è¿çº¿) --- */}
                            {viewMode === 'graph' && (
                                <div className="h-full flex relative overflow-hidden">
                                    
                                    {/* ğŸ’¡ 1. é™æ€èƒŒæ™¯è¿çº¿å±‚ (å›ºå®šåœ¨åº•å±‚) */}
                                    <svg className="absolute inset-0 w-full h-full pointer-events-none z-10">
                                        {workflow.shots?.map((shot, i) => {
                                            // è¿çº¿èµ·ç‚¹ï¼šå·¦ä¾§å®¹å™¨å®½ 350pxï¼ŒMaster Source åœ¨å…¶å‚ç›´ä¸­å¿ƒ
                                            const startX = 330; 
                                            const startY = containerHeight / 2;
                                            
                                            // è¿çº¿ç»ˆç‚¹ï¼šå³ä¾§åˆ†é•œåˆ—è¡¨çš„æ¯ä¸ª Shot çš„å·¦è¾¹ç¼˜ä¸­å¿ƒ
                                            // ç®—æ³•ï¼šåˆå§‹åç§» 40px + ç´¢å¼• i * è¡Œé«˜ 220px + è¡Œé«˜ä¸€åŠ 110px - æ»šåŠ¨ä½ç§»
                                            const endX = 420;
                                            const endY = (40 + i * 220 + 110) - scrollTop;
                                            
                                            // å¦‚æœç»ˆç‚¹è¶…å‡ºäº†å¯è§èŒƒå›´ï¼Œæ·¡åŒ–è¿çº¿
                                            const opacity = (endY < -50 || endY > containerHeight + 50) ? 0 : 1;

                                            return (
                                                <path key={i} 
                                                    d={`M ${startX} ${startY} C ${startX + 40} ${startY}, ${endX - 40} ${endY}, ${endX} ${endY}`} 
                                                    className={`node-line ${shot.status?.video_generate === 'RUNNING' || loading ? 'node-line-active' : ''}`}
                                                    style={{ strokeOpacity: opacity * (shot.status?.video_generate === 'SUCCESS' ? 0.6 : 0.15) }}
                                                />
                                            );
                                        })}
                                    </svg>

                                    {/* ğŸ’¡ 2. å·¦ä¾§å›ºå®šé¢æ¿ (ä¸æ»šåŠ¨) */}
                                    <div className="w-[350px] flex-shrink-0 flex items-center justify-center p-8 z-20 border-r border-white/5 relative bg-slate-950">
                                        <div className="glass p-6 rounded-[2.5rem] border-2 border-red-500/40 w-full shadow-[0_0_50px_rgba(239,68,68,0.15)] relative">
                                            {/* ç‰©ç†å‘å°„å­” */}
                                            <div className="absolute -right-1.5 top-1/2 -translate-y-1/2 w-3 h-3 bg-red-500 rounded-full shadow-[0_0_15px_#ef4444]"></div>
                                            
                                            <div className="flex items-center gap-3 mb-4">
                                                <div className="w-2 h-2 bg-red-500 rounded-full animate-pulse"></div>
                                                <h3 className="text-xs font-black tracking-widest uppercase text-red-500">Master Source</h3>
                                            </div>
                                            <div className="aspect-video bg-black rounded-2xl overflow-hidden mb-4 border border-white/10 flex items-center justify-center font-mono text-[10px] text-slate-500 italic text-center px-4">
                                                {workflow.source_video}
                                            </div>
                                            <div className="bg-white/5 p-3 rounded-xl border border-white/5">
                                                <p className="text-[9px] text-slate-500 uppercase font-black mb-1 tracking-widest">Decomposition Node</p>
                                                <p className="text-[10px] text-emerald-400 font-mono italic leading-tight">Segmenting input into {workflow.shots?.length} parallel tasks...</p>
                                            </div>
                                        </div>
                                    </div>

                                    {/* ğŸ’¡ 3. å³ä¾§æ»šåŠ¨åˆ—è¡¨ */}
                                    <div 
                                        className="flex-1 overflow-y-auto relative custom-scrollbar z-20" 
                                        onScroll={onScroll}
                                        ref={scrollRef}
                                    >
                                        <div className="py-10 pl-20 pr-10 space-y-0">
                                            {workflow.shots?.map((shot, i) => {
                                                const isSuccess = shot.status?.video_generate === 'SUCCESS';
                                                const isRunning = shot.status?.video_generate === 'RUNNING';
                                                return (
                                                    <div key={shot.shot_id} className="shot-row-container gap-6">
                                                        {/* è¾“å…¥å±‚ */}
                                                        <div className="w-56 glass p-3 rounded-2xl border border-white/10 text-[9px] relative transition-all duration-500 group">
                                                            {/* è¿çº¿æ¥æ”¶å­” */}
                                                            <div className="absolute -left-1.5 top-1/2 -translate-y-1/2 w-2.5 h-2.5 bg-blue-500 rounded-full shadow-[0_0_10px_#3b82f6]"></div>
                                                            <div className="text-blue-400 font-black tracking-widest uppercase mb-2">Input: Shot #{i+1}</div>
                                                            <div className="flex gap-2">
                                                                <img src={`/assets/${shot.assets?.first_frame}`} className="w-12 h-12 rounded-lg object-cover border border-white/10 shadow-lg" />
                                                                <div className="overflow-hidden">
                                                                    <p className="text-slate-400 font-mono truncate">{workflow.global?.style_prompt}</p>
                                                                    <p className="text-slate-500 italic truncate mt-1">"{shot.description}"</p>
                                                                </div>
                                                            </div>
                                                        </div>

                                                        <div className="text-slate-700 font-bold opacity-30 italic">âœ</div>

                                                        {/* å¤„ç†å¼•æ“ */}
                                                        <div className={`w-40 glass p-3 rounded-2xl border-2 flex flex-col items-center justify-center gap-1 transition-all duration-700 ${isRunning ? 'border-blue-500 bg-blue-500/10 scale-105' : isSuccess ? 'border-emerald-500/50' : 'border-white/10 opacity-40'}`}>
                                                            <span className="text-[8px] text-slate-500 uppercase font-black tracking-tighter">AI Processor</span>
                                                            <span className="text-[11px] font-bold font-mono">Veo 3.1</span>
                                                            <span className={`text-[7px] px-2 py-0.5 rounded-full font-bold uppercase tracking-widest ${isSuccess ? 'bg-emerald-500/20 text-emerald-400' : isRunning ? 'bg-blue-500/20 text-blue-400 animate-pulse' : 'bg-slate-800 text-slate-500'}`}>
                                                                {isSuccess ? 'COMPLETED' : isRunning ? 'WORKING' : 'WAITING'}
                                                            </span>
                                                        </div>

                                                        <div className="text-slate-700 font-bold opacity-30 italic">âœ</div>

                                                        {/* è¾“å‡ºèµ„æº */}
                                                        <div className={`w-64 glass p-2 rounded-2xl border transition-all duration-700 ${isSuccess ? 'border-emerald-500/40 bg-emerald-500/5 shadow-2xl scale-105' : 'border-white/5 opacity-40'}`}>
                                                            <div className="aspect-video bg-black rounded-xl overflow-hidden relative shadow-inner">
                                                                {isSuccess && shot.assets.video ? (
                                                                    <video src={`/assets/${shot.assets.video}`} className="w-full h-full object-cover" autoPlay muted loop />
                                                                ) : (
                                                                    <div className="h-full flex items-center justify-center text-[8px] text-slate-700 italic font-mono uppercase tracking-widest">asset_pending.mp4</div>
                                                                )}
                                                            </div>
                                                        </div>
                                                    </div>
                                                );
                                            })}
                                        </div>
                                    </div>
                                </div>
                            )}
                        </div>

                        {/* å³ä¾§ Agent äº¤äº’ */}
                        <div className="w-80 flex flex-col glass rounded-[2.5rem] overflow-hidden border border-white/10 shadow-2xl">
                            <div className="p-5 border-b border-white/5 bg-white/5 flex items-center gap-3">
                                <div className="w-2 h-2 bg-emerald-500 rounded-full animate-pulse shadow-[0_0_10px_#10b981]"></div>
                                <span className="text-xs font-black tracking-widest uppercase text-emerald-400 tracking-tighter">Director Agent</span>
                            </div>
                            <div className="flex-1 overflow-y-auto p-5 space-y-5 custom-scrollbar bg-slate-950/20 text-xs">
                                {messages.map((m, i) => (
                                    <div key={i} className={`flex ${m.role === 'user' ? 'justify-end' : 'justify-start'}`}>
                                        <div className={`max-w-[90%] p-3.5 rounded-2xl shadow-sm leading-relaxed ${m.role === 'user' ? 'bg-blue-600 text-white rounded-tr-none' : 'bg-slate-800 text-slate-200 rounded-tl-none border border-white/5'}`}>
                                            {m.text}
                                        </div>
                                    </div>
                                ))}
                                {loading && <div className="text-[10px] text-slate-500 font-mono animate-pulse text-center uppercase tracking-widest mt-2">Updating Neural Graph...</div>}
                            </div>
                            <div className="p-5 bg-slate-900/80 border-t border-white/10">
                                <div className="flex gap-2">
                                    <input value={inputText} onChange={e => setInputText(e.target.value)} onKeyDown={e => e.key === 'Enter' && sendAgentMsg()} placeholder="Command Agent..." className="flex-1 bg-slate-950 border border-white/10 rounded-xl px-4 py-2.5 text-xs outline-none focus:border-blue-500 text-white transition-all shadow-inner" />
                                    <button onClick={sendAgentMsg} className="bg-blue-600 hover:bg-blue-500 px-4 py-2.5 rounded-xl text-[10px] font-black uppercase transition-all active:scale-95 shadow-lg shadow-blue-900/30">Send</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            );
        };

        const root = ReactDOM.createRoot(document.getElementById('root'));
        root.render(<App />);
    </script>
</body>
</html>
</file>

<file path="core/runner.py">
# core/runner.py
from pathlib import Path
import shutil
import subprocess
import time
import os
import requests 

from .workflow_io import save_workflow, load_workflow


def ensure_videos_dir(job_dir: Path) -> Path:
    videos_dir = job_dir / "videos"
    videos_dir.mkdir(parents=True, exist_ok=True)
    return videos_dir


def mock_stylize_frame(job_dir: Path, shot: dict) -> str:
    src = job_dir / shot["assets"]["first_frame"]
    if not src.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° first_frameï¼š{src}")

    dst = job_dir / "stylized_frames" / f"{shot['shot_id']}.png"
    dst.parent.mkdir(parents=True, exist_ok=True)
    shutil.copyfile(src, dst)
    return f"stylized_frames/{dst.name}"


def mock_generate_video(job_dir: Path, shot: dict) -> str:
    videos_dir = ensure_videos_dir(job_dir)
    out_path = videos_dir / f"{shot['shot_id']}.mp4"
    
    # æ ¸å¿ƒï¼šå¯åŠ¨å‰æ¸…åœºï¼Œç¡®ä¿çŠ¶æ€åŒæ­¥å‡†ç¡®
    if out_path.exists():
        os.remove(out_path)

    src_video = job_dir / "input.mp4"
    if not src_video.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æºè§†é¢‘ï¼š{src_video}")
    ffmpeg = "/opt/homebrew/bin/ffmpeg"
    cmd = [
        ffmpeg, "-y",
        "-i", str(src_video),
        "-t", "1.0",
        "-c", "copy",
        str(out_path)
    ]
    subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    return f"videos/{out_path.name}"


def veo_generate_video(job_dir: Path, wf: dict, shot: dict) -> str:
    """
    Veo 3.1 å›¾ç”Ÿè§†é¢‘ - å¥å£®æ€§å¢å¼ºç‰ˆ
    1. å¢åŠ å®‰å…¨è¿‡æ»¤æ£€æŸ¥ï¼Œé˜²æ­¢ç©ºå¼•ç”¨å´©æºƒ
    2. ç”Ÿæˆå‰æ¸…ç†æ—§æ–‡ä»¶
    """
    from google import genai
    from google.genai import types

    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise RuntimeError("æ²¡æœ‰æ£€æµ‹åˆ° GEMINI_API_KEY ç¯å¢ƒå˜é‡")

    videos_dir = ensure_videos_dir(job_dir)
    out_path = videos_dir / f"{shot['shot_id']}.mp4"

    # --- å¯åŠ¨å‰æ¸…åœº ---
    if out_path.exists():
        print(f"ğŸ—‘ï¸ å‡†å¤‡ç”Ÿæˆæ–°è§†é¢‘ï¼Œæ¸…ç†æ—§æ–‡ä»¶: {out_path}")
        os.remove(out_path)

    img_rel = shot.get("assets", {}).get("stylized_frame")
    if not img_rel:
        raise RuntimeError("shot ç¼ºå°‘ assets.stylized_frame")
    img_path = job_dir / img_rel

    # 1. åˆå§‹åŒ–å®¢æˆ·ç«¯ (ç”Ÿæˆé˜¶æ®µç”¨ v1alpha)
    client = genai.Client(api_key=api_key, http_options={'api_version': 'v1alpha'})

    # 2. å‘èµ· Veo è¯·æ±‚
    print(f"ğŸš€ å‘èµ· Veo è¯·æ±‚ (Shot: {shot['shot_id']})...")
    operation = client.models.generate_videos(
        model="veo-3.1-generate-preview", 
        prompt=f"Cinematic video, {shot.get('description', '')}. Style: {wf.get('global', {}).get('style_prompt', '')}.",
        image=types.Image(
            image_bytes=img_path.read_bytes(),
            mime_type="image/png"
        ),
        config=types.GenerateVideosConfig(
            number_of_videos=1,
            duration_seconds=6.0
        ),
    )

    # 3. è½®è¯¢çŠ¶æ€
    print(f"â³ ä»»åŠ¡å·²æäº¤ï¼ŒVeo æ­£åœ¨ç”Ÿæˆè§†é¢‘ (çº¦ 1-3 åˆ†é’Ÿ)...")
    while not operation.done:
        time.sleep(20)
        operation = client.operations.get(operation)
        print(f"â³ ä»åœ¨ç”Ÿæˆä¸­...")

    if operation.error:
        raise RuntimeError(f"Veo åç«¯æŠ¥é”™: {operation.error}")

    # 4. ç»“æœæ£€æŸ¥ (é‡è¦ä¿®å¤ç‚¹ï¼šé˜²æ­¢å®‰å…¨è¿‡æ»¤å¯¼è‡´çš„å´©æºƒ)
    resp = operation.response
    if not resp or not hasattr(resp, 'generated_videos') or not resp.generated_videos:
        # å¦‚æœæ¨¡å‹å› ä¸ºå®‰å…¨ç­–ç•¥æ‹’ç»ç”Ÿæˆï¼Œresp.generated_videos ä¼šæ˜¯ None æˆ–ç©ºåˆ—è¡¨
        raise RuntimeError("Veo æœªè¿”å›è§†é¢‘å†…å®¹ã€‚è¿™é€šå¸¸ç”±äº Prompt è§¦å‘äº†å®‰å…¨è¿‡æ»¤æˆ–æ¨¡å‹ç”Ÿæˆå¼‚å¸¸ã€‚")

    video_obj = resp.generated_videos[0].video
    
    file_id = getattr(video_obj, 'name', None)
    if not file_id and hasattr(video_obj, 'uri'):
        file_id = f"files/{video_obj.uri.split('/')[-1]}"

    if not file_id:
        raise RuntimeError(f"æ— æ³•å®šä½ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶: {video_obj}")

    # 5. ä¸‹è½½è§†é¢‘
    print(f"âœ… ç”ŸæˆæˆåŠŸï¼Œæ­£åœ¨ä¸‹è½½è§†é¢‘...")
    download_url = f"https://generativelanguage.googleapis.com/v1beta/{file_id}"
    query_params = {'alt': 'media', 'key': api_key}

    try:
        response = requests.get(download_url, params=query_params, stream=True)
        if response.status_code != 200:
            alpha_url = f"https://generativelanguage.googleapis.com/v1alpha/{file_id}"
            response = requests.get(alpha_url, params=query_params, stream=True)

        if response.status_code == 200:
            with open(out_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=1024*1024): 
                    if chunk: f.write(chunk)
            print(f"ğŸ’¾ è§†é¢‘ç”Ÿæˆå¹¶ä¸‹è½½æˆåŠŸï¼æœ¬åœ°è·¯å¾„: {out_path}")
        else:
            raise RuntimeError(f"ä¸‹è½½å¤±è´¥ã€‚çŠ¶æ€ç : {response.status_code}")
            
    except Exception as e:
        print(f"âŒ ä¸‹è½½è¿‡ç¨‹å¼‚å¸¸: {e}")
        raise e

    return f"videos/{out_path.name}"


def run_stylize(job_dir: Path, wf: dict, target_shot: str | None = None) -> None:
    for shot in wf.get("shots", []):
        sid = shot.get("shot_id")
        if target_shot and sid != target_shot: continue
        status = shot.get("status", {}).get("stylize", "NOT_STARTED")
        if not target_shot and status not in ("NOT_STARTED", "FAILED"): continue
        shot.setdefault("status", {})["stylize"] = "RUNNING"
        save_workflow(job_dir, wf)
        try:
            rel_path = mock_stylize_frame(job_dir, shot)
            shot.setdefault("assets", {})["stylized_frame"] = rel_path
            shot["status"]["stylize"] = "SUCCESS"
            print(f"âœ… stylize SUCCESS: {sid} -> {rel_path}")
        except Exception as e:
            shot["status"]["stylize"] = "FAILED"
            shot.setdefault("errors", {})["stylize"] = str(e)
            print(f"âŒ stylize FAILED: {sid} -> {e}")
        save_workflow(job_dir, wf)


def run_video_generate(job_dir: Path, wf: dict, target_shot: str | None = None) -> None:
    for shot in wf.get("shots", []):
        sid = shot.get("shot_id")
        if target_shot and sid != target_shot: continue
        status = shot.get("status", {}).get("video_generate", "NOT_STARTED")
        if not target_shot and status not in ("NOT_STARTED", "FAILED"): continue
        shot.setdefault("status", {})["video_generate"] = "RUNNING"
        save_workflow(job_dir, wf)
        try:
            video_model = wf.get("global", {}).get("video_model", "mock")
            if video_model == "veo":
                print(f"ğŸ”¥ æ‰§è¡Œ Veo ä»»åŠ¡: {sid}")
                rel_video_path = veo_generate_video(job_dir, wf, shot)
            else:
                rel_video_path = mock_generate_video(job_dir, shot)
            shot.setdefault("assets", {})["video"] = rel_video_path
            shot["status"]["video_generate"] = "SUCCESS"
            print(f"âœ… video_generate SUCCESS: {sid}")
        except Exception as e:
            import traceback
            shot["status"]["video_generate"] = "FAILED"
            shot.setdefault("errors", {})["video_generate"] = str(e)
            print(f"âŒ video_generate FAILED: {sid}")
            traceback.print_exc()
        save_workflow(job_dir, wf)


def run_pipeline(job_dir: Path, target_shot: str | None = None) -> None:
    wf = load_workflow(job_dir)
    run_stylize(job_dir, wf, target_shot=target_shot)
    wf = load_workflow(job_dir)
    run_video_generate(job_dir, wf, target_shot=target_shot)
</file>

</files>
